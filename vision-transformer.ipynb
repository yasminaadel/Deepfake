{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10298344,"sourceType":"datasetVersion","datasetId":6374214}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom torchvision import transforms, datasets\nimport torch.optim as optim\nimport torch.nn as nn\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nfrom transformers import ViTForImageClassification, ViTFeatureExtractor\nimport optuna\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T10:48:52.828295Z","iopub.execute_input":"2024-12-27T10:48:52.828580Z","iopub.status.idle":"2024-12-27T10:48:52.833490Z","shell.execute_reply.started":"2024-12-27T10:48:52.828559Z","shell.execute_reply":"2024-12-27T10:48:52.832604Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"dataset_dir = '/kaggle/input/deepfake/DeepFake'\n\ntransform_train = transforms.Compose([\n    transforms.Resize((224, 224)),  \n    transforms.ToTensor(),  \n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(p=0.2),\n    transforms.RandomRotation(15),\n    transforms.RandomCrop(224, padding=10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.RandomAffine(degrees=20, scale=(0.8, 1.2), shear=10),\n    transforms.RandomErasing(p=0.3),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  \n])\n\ntransform_val_test = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T10:48:55.497751Z","iopub.execute_input":"2024-12-27T10:48:55.498070Z","iopub.status.idle":"2024-12-27T10:48:55.503733Z","shell.execute_reply.started":"2024-12-27T10:48:55.498037Z","shell.execute_reply":"2024-12-27T10:48:55.502954Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Load the dataset\nfrom torchvision.datasets import ImageFolder\ndataset = ImageFolder(root=dataset_dir, transform=transform_train)\nprint(\"Classes:\", dataset.classes)\nprint(\"Class-to-Index Mapping:\", dataset.class_to_idx)\nprint(\"Number of Samples:\", len(dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T10:49:07.422461Z","iopub.execute_input":"2024-12-27T10:49:07.422808Z","iopub.status.idle":"2024-12-27T10:49:52.137598Z","shell.execute_reply.started":"2024-12-27T10:49:07.422779Z","shell.execute_reply":"2024-12-27T10:49:52.136933Z"}},"outputs":[{"name":"stdout","text":"Classes: ['Fake', 'Real']\nClass-to-Index Mapping: {'Fake': 0, 'Real': 1}\nNumber of Samples: 10826\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# # Load ViT model from Hugging Face\n# def get_model():\n#     # Load pre-trained Vision Transformer model\n#     model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224-in21k\", num_labels=2)\n#     return model\n\ndef get_model():\n    # Load pre-trained Vision Transformer model\n    model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224-in21k\", num_labels=2)\n\n    # Freeze all layers except the classification head\n    for param in model.parameters():\n        param.requires_grad = False  # Freeze all parameters\n\n    # Ensure the classification head is trainable\n    for param in model.classifier.parameters():\n        param.requires_grad = True\n\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T13:41:40.466418Z","iopub.execute_input":"2024-12-27T13:41:40.466776Z","iopub.status.idle":"2024-12-27T13:41:40.471403Z","shell.execute_reply.started":"2024-12-27T13:41:40.466745Z","shell.execute_reply":"2024-12-27T13:41:40.470561Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Calculate metrics function\ndef calculate_metrics(model, loader, device):\n    # Set the model to evaluation mode (disables dropout)\n    model.eval()\n\n    # Lists to store true labels and predicted labels\n    all_labels = []\n    all_predictions = []\n\n    # Disabling gradient computation\n    with torch.no_grad():\n        for images, labels in loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images).logits\n            # Get predicted labels by taking the argmax (most likely class)\n            _, predicted = torch.max(outputs, 1)\n            all_labels.extend(labels.cpu().numpy())\n            all_predictions.extend(predicted.cpu().numpy())\n\n    # Calculate the confusion matrix, which gives TN, FP, FN, and TP\n    conf_matrix = confusion_matrix(all_labels, all_predictions)\n    # Unpack the confusion matrix into four components: TN, FP, FN, TP\n    TN, FP, FN, TP = conf_matrix.ravel()\n\n    total = conf_matrix.sum()\n    accuracy = (TP + TN) / total if total > 0 else 0.0\n    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n\n    return accuracy, precision, recall, f1, conf_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T13:41:46.562703Z","iopub.execute_input":"2024-12-27T13:41:46.563015Z","iopub.status.idle":"2024-12-27T13:41:46.570036Z","shell.execute_reply.started":"2024-12-27T13:41:46.562991Z","shell.execute_reply":"2024-12-27T13:41:46.568956Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Train the model function with validation accuracy printed after each epoch\ndef train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5):\n    # Variable to track the best validation accuracy\n    best_val_accuracy = 0\n\n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        # Iterate over batches in the training data\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images).logits\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n        # Validation phase\n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images).logits\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n        val_accuracy = 100 * correct / total\n        print(f\"Epoch {epoch+1}/{epochs}, Validation Accuracy: {val_accuracy:.2f}%\")\n\n        if val_accuracy > best_val_accuracy:\n            best_val_accuracy = val_accuracy\n\n    return best_val_accuracy\n\n# Device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Cross-validation setup\nnum_folds = 3\nkf = KFold(n_splits=num_folds, shuffle=True, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T13:41:53.201728Z","iopub.execute_input":"2024-12-27T13:41:53.202054Z","iopub.status.idle":"2024-12-27T13:41:53.209356Z","shell.execute_reply.started":"2024-12-27T13:41:53.202023Z","shell.execute_reply":"2024-12-27T13:41:53.208559Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def objective(trial):\n    # Get a suggested learning rate from Optuna\n    lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\n    \n    # Initialize the model\n    model = get_model().to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n\n    val_accuracies = []\n    for fold_idx, (train_val_idx, test_idx) in enumerate(kf.split(dataset)):\n        print(f\"Fold {fold_idx + 1}/{num_folds}\")\n\n        # Create training/validation split\n        train_val_data = Subset(dataset, train_val_idx)\n        test_data = Subset(dataset, test_idx)\n\n        train_size = int(0.8 * len(train_val_data))\n        val_size = len(train_val_data) - train_size\n        train_data, val_data = torch.utils.data.random_split(\n            train_val_data, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n        )\n        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n\n        # Train the model and get validation accuracy\n        train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)\n\n        # Evaluate on validation set\n        val_accuracy, _, _, _, _ = calculate_metrics(model, val_loader, device)\n        val_accuracies.append(val_accuracy)\n\n    # Return the average validation accuracy across all folds as the objective value\n    return np.mean(val_accuracies)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T13:41:59.012537Z","iopub.execute_input":"2024-12-27T13:41:59.012878Z","iopub.status.idle":"2024-12-27T13:41:59.019536Z","shell.execute_reply.started":"2024-12-27T13:41:59.012850Z","shell.execute_reply":"2024-12-27T13:41:59.018508Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def evaluate_test_set(best_lr):\n    # best_lr=1e-4 \n    # Initialize model with the best learning rate\n    model = get_model().to(device)\n    optimizer = optim.Adam(model.parameters(), lr=best_lr)\n    criterion = nn.CrossEntropyLoss()\n\n    fold_metrics = []\n    for fold_idx, (train_val_idx, test_idx) in enumerate(kf.split(dataset)):\n        print(f\"\\nEvaluating on Fold {fold_idx + 1}/{num_folds}\")\n\n        # Create training/validation split\n        train_val_data = Subset(dataset, train_val_idx)\n        test_data = Subset(dataset, test_idx)\n\n        train_size = int(0.8 * len(train_val_data))\n        val_size = len(train_val_data) - train_size\n        train_data, val_data = torch.utils.data.random_split(\n            train_val_data, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n        )\n        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n\n        # Train the model\n        train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)\n\n        # Evaluate on the test set\n        test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n        fold_metrics.append(calculate_metrics(model, test_loader, device))\n\n    # Print metrics for each fold\n    for fold_idx, metrics in enumerate(fold_metrics):\n        accuracy, precision, recall, f1, conf_matrix = metrics\n        print(f\"Fold {fold_idx + 1} Metrics:\")\n        print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}\")\n        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n\n    # Calculate average metrics across folds\n    avg_accuracy = np.mean([metrics[0] for metrics in fold_metrics])\n    avg_precision = np.mean([metrics[1] for metrics in fold_metrics])\n    avg_recall = np.mean([metrics[2] for metrics in fold_metrics])\n    avg_f1 = np.mean([metrics[3] for metrics in fold_metrics])\n    total_conf_matrix = np.sum([metrics[4] for metrics in fold_metrics], axis=0)\n\n    print(\"\\nAverage Metrics Across Folds:\")\n    print(f\"Accuracy: {avg_accuracy:.2f}, Precision: {avg_precision:.2f}, Recall: {avg_recall:.2f}, F1-Score: {avg_f1:.2f}\")\n    print(f\"Confusion Matrix (sum of all folds):\\n{total_conf_matrix}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T13:42:04.884125Z","iopub.execute_input":"2024-12-27T13:42:04.884455Z","iopub.status.idle":"2024-12-27T13:42:04.892376Z","shell.execute_reply.started":"2024-12-27T13:42:04.884422Z","shell.execute_reply":"2024-12-27T13:42:04.891533Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Optuna Optimization and Final Testing\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=5)\n\n# Best learning rate found for the model\nbest_lr = study.best_params['lr']\nprint(f\"Best Learning Rate: {best_lr}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T13:42:10.647575Z","iopub.execute_input":"2024-12-27T13:42:10.647939Z","iopub.status.idle":"2024-12-27T17:36:17.306321Z","shell.execute_reply.started":"2024-12-27T13:42:10.647909Z","shell.execute_reply":"2024-12-27T17:36:17.305559Z"}},"outputs":[{"name":"stderr","text":"[I 2024-12-27 13:42:10,649] A new study created in memory with name: no-name-fd96b736-c879-4253-b3f3-5c779d59cd7d\n<ipython-input-23-c26ac5e860dc>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\nSome weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Fold 1/3\nEpoch 1/5, Loss: 0.6507720100945531\nEpoch 1/5, Validation Accuracy: 65.58%\nEpoch 2/5, Loss: 0.6074476215720835\nEpoch 2/5, Validation Accuracy: 65.79%\nEpoch 3/5, Loss: 0.5820526097031588\nEpoch 3/5, Validation Accuracy: 68.49%\nEpoch 4/5, Loss: 0.5730969117161977\nEpoch 4/5, Validation Accuracy: 70.29%\nEpoch 5/5, Loss: 0.5587431156174254\nEpoch 5/5, Validation Accuracy: 69.67%\nFold 2/3\nEpoch 1/5, Loss: 0.5516741998617162\nEpoch 1/5, Validation Accuracy: 73.82%\nEpoch 2/5, Loss: 0.5452957089105364\nEpoch 2/5, Validation Accuracy: 71.54%\nEpoch 3/5, Loss: 0.5386908796940061\nEpoch 3/5, Validation Accuracy: 73.61%\nEpoch 4/5, Loss: 0.5312517698627809\nEpoch 4/5, Validation Accuracy: 74.31%\nEpoch 5/5, Loss: 0.5269796095829642\nEpoch 5/5, Validation Accuracy: 74.72%\nFold 3/3\nEpoch 1/5, Loss: 0.5263953190811431\nEpoch 1/5, Validation Accuracy: 74.58%\nEpoch 2/5, Loss: 0.5164344542922236\nEpoch 2/5, Validation Accuracy: 75.07%\nEpoch 3/5, Loss: 0.5181793328477533\nEpoch 3/5, Validation Accuracy: 76.11%\nEpoch 4/5, Loss: 0.5116881650785057\nEpoch 4/5, Validation Accuracy: 74.38%\nEpoch 5/5, Loss: 0.5108066431725222\nEpoch 5/5, Validation Accuracy: 75.90%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-27 14:28:59,905] Trial 0 finished with value: 0.7373037857802401 and parameters: {'lr': 0.00025465581389399783}. Best is trial 0 with value: 0.7373037857802401.\n<ipython-input-23-c26ac5e860dc>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\nSome weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Fold 1/3\nEpoch 1/5, Loss: 0.6854748916889423\nEpoch 1/5, Validation Accuracy: 60.94%\nEpoch 2/5, Loss: 0.664071887237591\nEpoch 2/5, Validation Accuracy: 63.30%\nEpoch 3/5, Loss: 0.6456661876393945\nEpoch 3/5, Validation Accuracy: 65.10%\nEpoch 4/5, Loss: 0.6337598061693307\nEpoch 4/5, Validation Accuracy: 64.68%\nEpoch 5/5, Loss: 0.6256675061599984\nEpoch 5/5, Validation Accuracy: 65.86%\nFold 2/3\nEpoch 1/5, Loss: 0.6179143279296917\nEpoch 1/5, Validation Accuracy: 67.59%\nEpoch 2/5, Loss: 0.6083942990935309\nEpoch 2/5, Validation Accuracy: 70.71%\nEpoch 3/5, Loss: 0.6040340662002563\nEpoch 3/5, Validation Accuracy: 69.39%\nEpoch 4/5, Loss: 0.5998525286906332\nEpoch 4/5, Validation Accuracy: 68.07%\nEpoch 5/5, Loss: 0.5953022032482189\nEpoch 5/5, Validation Accuracy: 68.14%\nFold 3/3\nEpoch 1/5, Loss: 0.5893637745419918\nEpoch 1/5, Validation Accuracy: 70.84%\nEpoch 2/5, Loss: 0.5831466356693711\nEpoch 2/5, Validation Accuracy: 70.91%\nEpoch 3/5, Loss: 0.5800033485033236\nEpoch 3/5, Validation Accuracy: 71.26%\nEpoch 4/5, Loss: 0.5811527088202165\nEpoch 4/5, Validation Accuracy: 70.64%\nEpoch 5/5, Loss: 0.5731387362295751\nEpoch 5/5, Validation Accuracy: 72.85%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-27 15:15:35,699] Trial 1 finished with value: 0.6789012003693443 and parameters: {'lr': 4.9454827357262526e-05}. Best is trial 0 with value: 0.7373037857802401.\n<ipython-input-23-c26ac5e860dc>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\nSome weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Fold 1/3\nEpoch 1/5, Loss: 0.6151817480503525\nEpoch 1/5, Validation Accuracy: 70.01%\nEpoch 2/5, Loss: 0.5636429152765327\nEpoch 2/5, Validation Accuracy: 71.88%\nEpoch 3/5, Loss: 0.5443127688781991\nEpoch 3/5, Validation Accuracy: 72.09%\nEpoch 4/5, Loss: 0.5309957092967481\nEpoch 4/5, Validation Accuracy: 72.78%\nEpoch 5/5, Loss: 0.5276266552137406\nEpoch 5/5, Validation Accuracy: 73.89%\nFold 2/3\nEpoch 1/5, Loss: 0.5145015640812025\nEpoch 1/5, Validation Accuracy: 76.04%\nEpoch 2/5, Loss: 0.509147295141747\nEpoch 2/5, Validation Accuracy: 74.52%\nEpoch 3/5, Loss: 0.4981786832625036\nEpoch 3/5, Validation Accuracy: 76.59%\nEpoch 4/5, Loss: 0.5006659852536344\nEpoch 4/5, Validation Accuracy: 76.80%\nEpoch 5/5, Loss: 0.4899695808716242\nEpoch 5/5, Validation Accuracy: 78.05%\nFold 3/3\nEpoch 1/5, Loss: 0.4957110384551201\nEpoch 1/5, Validation Accuracy: 75.48%\nEpoch 2/5, Loss: 0.4889793801044232\nEpoch 2/5, Validation Accuracy: 77.91%\nEpoch 3/5, Loss: 0.48901270618096243\nEpoch 3/5, Validation Accuracy: 76.59%\nEpoch 4/5, Loss: 0.4846448761652846\nEpoch 4/5, Validation Accuracy: 79.09%\nEpoch 5/5, Loss: 0.4835608677310838\nEpoch 5/5, Validation Accuracy: 78.19%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-27 16:03:15,474] Trial 2 finished with value: 0.7606186518928902 and parameters: {'lr': 0.000714013461817952}. Best is trial 2 with value: 0.7606186518928902.\n<ipython-input-23-c26ac5e860dc>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\nSome weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Fold 1/3\nEpoch 1/5, Loss: 0.6296635652115332\nEpoch 1/5, Validation Accuracy: 70.22%\nEpoch 2/5, Loss: 0.5766330158842202\nEpoch 2/5, Validation Accuracy: 69.94%\nEpoch 3/5, Loss: 0.5522669664074703\nEpoch 3/5, Validation Accuracy: 72.23%\nEpoch 4/5, Loss: 0.5337891483175162\nEpoch 4/5, Validation Accuracy: 74.24%\nEpoch 5/5, Loss: 0.5244410052813219\nEpoch 5/5, Validation Accuracy: 74.03%\nFold 2/3\nEpoch 1/5, Loss: 0.5215849395614961\nEpoch 1/5, Validation Accuracy: 75.42%\nEpoch 2/5, Loss: 0.5192068021600418\nEpoch 2/5, Validation Accuracy: 74.58%\nEpoch 3/5, Loss: 0.5099655929849951\nEpoch 3/5, Validation Accuracy: 75.90%\nEpoch 4/5, Loss: 0.5072653545529803\nEpoch 4/5, Validation Accuracy: 76.59%\nEpoch 5/5, Loss: 0.5038440604565552\nEpoch 5/5, Validation Accuracy: 75.90%\nFold 3/3\nEpoch 1/5, Loss: 0.49815536582667524\nEpoch 1/5, Validation Accuracy: 77.08%\nEpoch 2/5, Loss: 0.4901683954573468\nEpoch 2/5, Validation Accuracy: 75.97%\nEpoch 3/5, Loss: 0.4903637002844837\nEpoch 3/5, Validation Accuracy: 77.29%\nEpoch 4/5, Loss: 0.4896264431884934\nEpoch 4/5, Validation Accuracy: 76.32%\nEpoch 5/5, Loss: 0.49430161599296235\nEpoch 5/5, Validation Accuracy: 76.87%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-27 16:49:53,876] Trial 3 finished with value: 0.754847645429363 and parameters: {'lr': 0.0005412547906199882}. Best is trial 2 with value: 0.7606186518928902.\n<ipython-input-23-c26ac5e860dc>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\nSome weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Fold 1/3\nEpoch 1/5, Loss: 0.6851157700817888\nEpoch 1/5, Validation Accuracy: 59.42%\nEpoch 2/5, Loss: 0.6696002275904239\nEpoch 2/5, Validation Accuracy: 64.27%\nEpoch 3/5, Loss: 0.6590851008562751\nEpoch 3/5, Validation Accuracy: 65.30%\nEpoch 4/5, Loss: 0.6469956883409406\nEpoch 4/5, Validation Accuracy: 66.00%\nEpoch 5/5, Loss: 0.6392336695233761\nEpoch 5/5, Validation Accuracy: 64.47%\nFold 2/3\nEpoch 1/5, Loss: 0.6319607595053826\nEpoch 1/5, Validation Accuracy: 66.83%\nEpoch 2/5, Loss: 0.6243452897387973\nEpoch 2/5, Validation Accuracy: 67.80%\nEpoch 3/5, Loss: 0.6163702366760423\nEpoch 3/5, Validation Accuracy: 67.94%\nEpoch 4/5, Loss: 0.6151017375413884\nEpoch 4/5, Validation Accuracy: 68.84%\nEpoch 5/5, Loss: 0.608903912220212\nEpoch 5/5, Validation Accuracy: 67.87%\nFold 3/3\nEpoch 1/5, Loss: 0.6027382256576369\nEpoch 1/5, Validation Accuracy: 69.39%\nEpoch 2/5, Loss: 0.5986595904629534\nEpoch 2/5, Validation Accuracy: 70.29%\nEpoch 3/5, Loss: 0.5984369648095652\nEpoch 3/5, Validation Accuracy: 70.01%\nEpoch 4/5, Loss: 0.5909344066572453\nEpoch 4/5, Validation Accuracy: 69.39%\nEpoch 5/5, Loss: 0.5881415450770552\nEpoch 5/5, Validation Accuracy: 69.94%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-27 17:36:17,301] Trial 4 finished with value: 0.6849030470914128 and parameters: {'lr': 3.389146247036404e-05}. Best is trial 2 with value: 0.7606186518928902.\n","output_type":"stream"},{"name":"stdout","text":"Best Learning Rate: 0.000714013461817952\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Evaluate on test sets for each fold\nevaluate_test_set()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T22:14:26.114419Z","iopub.execute_input":"2024-12-26T22:14:26.114699Z","iopub.status.idle":"2024-12-26T23:30:31.575532Z","shell.execute_reply.started":"2024-12-26T22:14:26.114678Z","shell.execute_reply":"2024-12-26T23:30:31.574695Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a30a5e0996a4e3f89f232ef0287760d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49dd4f43fcc845deb12f6a5058577805"}},"metadata":{}},{"name":"stderr","text":"Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nEvaluating on Fold 1/3\nEpoch 1/5, Loss: 0.45608829636929443\nEpoch 1/5, Validation Accuracy: 84.21%\nEpoch 2/5, Loss: 0.30265648660985806\nEpoch 2/5, Validation Accuracy: 85.94%\nEpoch 3/5, Loss: 0.26304742269917747\nEpoch 3/5, Validation Accuracy: 86.36%\nEpoch 4/5, Loss: 0.2523319789141581\nEpoch 4/5, Validation Accuracy: 88.57%\nEpoch 5/5, Loss: 0.21244480477347558\nEpoch 5/5, Validation Accuracy: 87.60%\n\nEvaluating on Fold 2/3\nEpoch 1/5, Loss: 0.23238328173344966\nEpoch 1/5, Validation Accuracy: 90.93%\nEpoch 2/5, Loss: 0.20780114862470997\nEpoch 2/5, Validation Accuracy: 91.69%\nEpoch 3/5, Loss: 0.19050432776630913\nEpoch 3/5, Validation Accuracy: 90.17%\nEpoch 4/5, Loss: 0.18332237678255825\nEpoch 4/5, Validation Accuracy: 92.80%\nEpoch 5/5, Loss: 0.17977310052316492\nEpoch 5/5, Validation Accuracy: 91.69%\n\nEvaluating on Fold 3/3\nEpoch 1/5, Loss: 0.18581577114637385\nEpoch 1/5, Validation Accuracy: 92.04%\nEpoch 2/5, Loss: 0.17143920283167732\nEpoch 2/5, Validation Accuracy: 89.89%\nEpoch 3/5, Loss: 0.1666674425218316\nEpoch 3/5, Validation Accuracy: 91.48%\nEpoch 4/5, Loss: 0.14778446242501392\nEpoch 4/5, Validation Accuracy: 91.62%\nEpoch 5/5, Loss: 0.14029216160997748\nEpoch 5/5, Validation Accuracy: 92.66%\nFold 1 Metrics:\nAccuracy: 0.89, Precision: 0.92, Recall: 0.85, F1-Score: 0.89\nConfusion Matrix:\n[[1709  132]\n [ 259 1509]]\nFold 2 Metrics:\nAccuracy: 0.92, Precision: 0.94, Recall: 0.89, F1-Score: 0.91\nConfusion Matrix:\n[[1704  103]\n [ 203 1599]]\nFold 3 Metrics:\nAccuracy: 0.93, Precision: 0.90, Recall: 0.97, F1-Score: 0.94\nConfusion Matrix:\n[[1571  194]\n [  49 1794]]\n\nAverage Metrics Across Folds:\nAccuracy: 0.91, Precision: 0.92, Recall: 0.90, F1-Score: 0.91\nConfusion Matrix (sum of all folds):\n[[4984  429]\n [ 511 4902]]\n","output_type":"stream"}],"execution_count":8}]}