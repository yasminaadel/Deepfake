{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10289603,"sourceType":"datasetVersion","datasetId":6368050}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom torchvision import transforms, models, datasets\nimport torch.optim as optim\nimport torch.nn as nn\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, precision_recall_fscore_support)\nfrom transformers import ViTForImageClassification, ViTFeatureExtractor\nimport optuna\nfrom torchvision.datasets import ImageFolder","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-25T17:34:29.881330Z","iopub.execute_input":"2024-12-25T17:34:29.881594Z","iopub.status.idle":"2024-12-25T17:34:42.654309Z","shell.execute_reply.started":"2024-12-25T17:34:29.881561Z","shell.execute_reply":"2024-12-25T17:34:42.653466Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"dataset_dir = '/kaggle/input/deepfake/DeepFake'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T17:34:59.760596Z","iopub.execute_input":"2024-12-25T17:34:59.760917Z","iopub.status.idle":"2024-12-25T17:34:59.764497Z","shell.execute_reply.started":"2024-12-25T17:34:59.760889Z","shell.execute_reply":"2024-12-25T17:34:59.763532Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"transform_train = transforms.Compose([\n    transforms.Resize((224, 224)),  \n    transforms.ToTensor(),  \n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(p=0.2),\n    transforms.RandomRotation(15),\n    transforms.RandomCrop(224, padding=10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.RandomAffine(degrees=20, scale=(0.8, 1.2), shear=10),\n    transforms.RandomErasing(p=0.3),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  \n])\n\ntransform_val_test = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T17:35:04.356765Z","iopub.execute_input":"2024-12-25T17:35:04.357072Z","iopub.status.idle":"2024-12-25T17:35:04.363179Z","shell.execute_reply.started":"2024-12-25T17:35:04.357044Z","shell.execute_reply":"2024-12-25T17:35:04.362390Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Load the dataset\ndataset = ImageFolder(root=dataset_dir, transform=transform_train)\nprint(\"Classes:\", dataset.classes)\nprint(\"Class-to-Index Mapping:\", dataset.class_to_idx)\nprint(\"Number of Samples:\", len(dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T17:35:08.105772Z","iopub.execute_input":"2024-12-25T17:35:08.106048Z","iopub.status.idle":"2024-12-25T17:35:23.272589Z","shell.execute_reply.started":"2024-12-25T17:35:08.106026Z","shell.execute_reply":"2024-12-25T17:35:23.271907Z"}},"outputs":[{"name":"stdout","text":"Classes: ['Fake', 'Real']\nClass-to-Index Mapping: {'Fake': 0, 'Real': 1}\nNumber of Samples: 10826\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"#def get_model(model_name):\n#    if model_name == \"densenet121\":\n#        model = models.densenet121(pretrained=True)\n#        # Modify the classifier for 2 output classes\n#        model.classifier = nn.Linear(model.classifier.in_features, 2)\n#        return model\ndef get_model(model_name):\n    if model_name == \"densenet121\":\n        # Load pre-trained DenseNet-121\n        model = models.densenet121(pretrained=True)\n        \n        # Freeze all layers except the classifier\n        for param in model.parameters():\n            param.requires_grad = False\n        \n        # Unfreeze the fully connected (classifier) layers\n        for param in model.classifier.parameters():\n            param.requires_grad = True\n        \n        # Modify the classifier for 2 output classes (binary classification)\n        model.classifier = nn.Linear(model.classifier.in_features, 2)\n        \n        return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T03:33:27.570058Z","iopub.execute_input":"2024-12-25T03:33:27.570341Z","iopub.status.idle":"2024-12-25T03:33:27.574724Z","shell.execute_reply.started":"2024-12-25T03:33:27.570318Z","shell.execute_reply":"2024-12-25T03:33:27.573934Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Calculate metrics function\ndef calculate_metrics(model, loader, device):\n    \n    # Set the model to evaluation mode (disables dropout)\n    model.eval()\n\n    # Lists to store true labels and predicted labels\n    all_labels = []\n    all_predictions = []\n\n    # Disabling gradient computation\n    with torch.no_grad():\n        for images, labels in loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n             # Get predicted labels by taking the argmax (most likely class)\n            _, predicted = torch.max(outputs, 1)\n            all_labels.extend(labels.cpu().numpy())\n            all_predictions.extend(predicted.cpu().numpy())\n\n     # Calculate the confusion matrix,which give TN, FP, FN, and TP\n    conf_matrix = confusion_matrix(all_labels, all_predictions)\n    # Unpack the confusion matrix into four components: TN, FP, FN, TP\n    TN, FP, FN, TP = conf_matrix.ravel() \n\n    total = conf_matrix.sum()\n    accuracy = (TP + TN) / total if total > 0 else 0.0\n    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n    \n    return accuracy, precision, recall, f1, conf_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T17:35:28.438167Z","iopub.execute_input":"2024-12-25T17:35:28.438508Z","iopub.status.idle":"2024-12-25T17:35:28.444908Z","shell.execute_reply.started":"2024-12-25T17:35:28.438478Z","shell.execute_reply":"2024-12-25T17:35:28.443870Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Train the model function with validation accuracy printed after each epoch\ndef train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5):\n    # Variable to track the best validation accuracy\n    best_val_accuracy = 0\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n         # Iterate over batches in the training data\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n        \n        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n        # Validation phase\n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        val_accuracy = 100 * correct / total\n        print(f\"Epoch {epoch+1}/{epochs}, Validation Accuracy: {val_accuracy:.2f}%\")\n        \n        if val_accuracy > best_val_accuracy:\n            best_val_accuracy = val_accuracy\n    \n    return best_val_accuracy\n\n# Device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Cross-validation setup\nnum_folds = 3\nkf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T17:35:32.629925Z","iopub.execute_input":"2024-12-25T17:35:32.630257Z","iopub.status.idle":"2024-12-25T17:35:32.706605Z","shell.execute_reply.started":"2024-12-25T17:35:32.630228Z","shell.execute_reply":"2024-12-25T17:35:32.705611Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def objective(trial, model_name):\n    # Get a suggested learning rate from Optuna\n    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n    \n    # Initialize the model with dropout\n    model = get_model(model_name).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    \n    val_accuracies = []\n    for fold_idx, (train_val_idx, test_idx) in enumerate(kf.split(dataset)):\n        print(f\"Fold {fold_idx + 1}/{num_folds}\")\n        \n        # Create training/validation split\n        train_val_data = Subset(dataset, train_val_idx)\n        test_data = Subset(dataset, test_idx)\n        \n        train_size = int(0.8 * len(train_val_data))\n        val_size = len(train_val_data) - train_size\n        train_data, val_data = torch.utils.data.random_split(\n            train_val_data, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n        )\n        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n        \n        # Train the model and get validation accuracy\n        train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)\n        \n        # Evaluate on validation set\n        val_accuracy, _, _, _, _ = calculate_metrics(model, val_loader, device)\n        val_accuracies.append(val_accuracy)\n    \n    # Return the average validation accuracy across all folds as the objective value\n    return np.mean(val_accuracies)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T03:33:27.700007Z","iopub.execute_input":"2024-12-25T03:33:27.700260Z","iopub.status.idle":"2024-12-25T03:33:27.717495Z","shell.execute_reply.started":"2024-12-25T03:33:27.700238Z","shell.execute_reply":"2024-12-25T03:33:27.716792Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def evaluate_test_set(model_name, best_lr):\n    # Initialize model with the best learning rate\n    model = get_model(model_name).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=best_lr)\n    criterion = nn.CrossEntropyLoss()\n\n    fold_metrics = []\n    for fold_idx, (train_val_idx, test_idx) in enumerate(kf.split(dataset)):\n        print(f\"\\nEvaluating on Fold {fold_idx + 1}/{num_folds}\")\n        \n        # Create training/validation split\n        train_val_data = Subset(dataset, train_val_idx)\n        test_data = Subset(dataset, test_idx)\n        \n        train_size = int(0.8 * len(train_val_data))\n        val_size = len(train_val_data) - train_size\n        train_data, val_data = torch.utils.data.random_split(\n            train_val_data, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n        )\n        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n        \n        # Train the model\n        train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)\n        \n        # Evaluate on the test set\n        test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n        fold_metrics.append(calculate_metrics(model, test_loader, device))\n    \n    # Print metrics for each fold\n    for fold_idx, metrics in enumerate(fold_metrics):\n        accuracy, precision, recall, f1, conf_matrix = metrics\n        print(f\"Fold {fold_idx + 1} Metrics:\")\n        print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}\")\n        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n\n# Calculate average metrics across folds\n    avg_accuracy = np.mean([metrics[0] for metrics in fold_metrics])\n    avg_precision = np.mean([metrics[1] for metrics in fold_metrics])\n    avg_recall = np.mean([metrics[2] for metrics in fold_metrics])\n    avg_f1 = np.mean([metrics[3] for metrics in fold_metrics])\n    total_conf_matrix = np.sum([metrics[4] for metrics in fold_metrics], axis=0)\n\n    print(\"\\nAverage Metrics Across Folds:\")\n    print(f\"Accuracy: {avg_accuracy:.2f}, Precision: {avg_precision:.2f}, Recall: {avg_recall:.2f}, F1-Score: {avg_f1:.2f}\")\n    print(f\"Confusion Matrix (sum of all folds):\\n{total_conf_matrix}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T03:33:27.718376Z","iopub.execute_input":"2024-12-25T03:33:27.718635Z","iopub.status.idle":"2024-12-25T03:33:27.732353Z","shell.execute_reply.started":"2024-12-25T03:33:27.718615Z","shell.execute_reply":"2024-12-25T03:33:27.731652Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Optuna Optimization and Final Testing\nfor model_name in [\"densenet121\"]:\n    print(f\"\\nOptimizing for {model_name.upper()}...\")\n    study = optuna.create_study(direction='maximize')\n    study.optimize(lambda trial: objective(trial, model_name), n_trials=5)  \n\n    # Best learning rate found for the model\n    best_lr = study.best_params['lr']\n    print(f\"Best Learning Rate for {model_name.upper()}: {best_lr}\")\n\n    # Evaluate on test sets for each fold\n    evaluate_test_set(model_name, best_lr)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T03:33:27.733014Z","iopub.execute_input":"2024-12-25T03:33:27.733282Z","iopub.status.idle":"2024-12-25T06:33:05.698058Z","shell.execute_reply.started":"2024-12-25T03:33:27.733255Z","shell.execute_reply":"2024-12-25T06:33:05.697186Z"}},"outputs":[{"name":"stderr","text":"[I 2024-12-25 03:33:27,749] A new study created in memory with name: no-name-42b87c05-09de-4088-8dc6-e05fd93c3908\n","output_type":"stream"},{"name":"stdout","text":"\nOptimizing for DENSENET121...\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-8-2e749100ab16>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n100%|██████████| 30.8M/30.8M [00:00<00:00, 88.0MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Fold 1/3\nEpoch 1/5, Loss: 0.7083361425452469\nEpoch 1/5, Validation Accuracy: 50.42%\nEpoch 2/5, Loss: 0.6887235483411926\nEpoch 2/5, Validation Accuracy: 55.96%\nEpoch 3/5, Loss: 0.6776838855848787\nEpoch 3/5, Validation Accuracy: 57.34%\nEpoch 4/5, Loss: 0.6646247285505684\nEpoch 4/5, Validation Accuracy: 60.94%\nEpoch 5/5, Loss: 0.6535120016962125\nEpoch 5/5, Validation Accuracy: 62.05%\nFold 2/3\nEpoch 1/5, Loss: 0.6493049995016656\nEpoch 1/5, Validation Accuracy: 64.47%\nEpoch 2/5, Loss: 0.6398751966202456\nEpoch 2/5, Validation Accuracy: 65.93%\nEpoch 3/5, Loss: 0.6351944109352913\nEpoch 3/5, Validation Accuracy: 64.54%\nEpoch 4/5, Loss: 0.6292336533741397\nEpoch 4/5, Validation Accuracy: 65.79%\nEpoch 5/5, Loss: 0.6197133610920352\nEpoch 5/5, Validation Accuracy: 65.72%\nFold 3/3\nEpoch 1/5, Loss: 0.6151255382358699\nEpoch 1/5, Validation Accuracy: 66.83%\nEpoch 2/5, Loss: 0.6181266838015772\nEpoch 2/5, Validation Accuracy: 68.84%\nEpoch 3/5, Loss: 0.6010530416478109\nEpoch 3/5, Validation Accuracy: 68.35%\nEpoch 4/5, Loss: 0.6094313314935779\nEpoch 4/5, Validation Accuracy: 68.42%\nEpoch 5/5, Loss: 0.60137222172147\nEpoch 5/5, Validation Accuracy: 70.43%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 04:03:29,439] Trial 0 finished with value: 0.6606648199445984 and parameters: {'lr': 2.8258362953509898e-05}. Best is trial 0 with value: 0.6606648199445984.\n<ipython-input-8-2e749100ab16>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Fold 1/3\nEpoch 1/5, Loss: 0.6828968442606004\nEpoch 1/5, Validation Accuracy: 60.94%\nEpoch 2/5, Loss: 0.6476617518050894\nEpoch 2/5, Validation Accuracy: 64.20%\nEpoch 3/5, Loss: 0.6291805986541411\nEpoch 3/5, Validation Accuracy: 66.41%\nEpoch 4/5, Loss: 0.6142049766047883\nEpoch 4/5, Validation Accuracy: 67.94%\nEpoch 5/5, Loss: 0.6059310276534676\nEpoch 5/5, Validation Accuracy: 68.56%\nFold 2/3\nEpoch 1/5, Loss: 0.5965159041446876\nEpoch 1/5, Validation Accuracy: 70.36%\nEpoch 2/5, Loss: 0.5957331934027909\nEpoch 2/5, Validation Accuracy: 68.01%\nEpoch 3/5, Loss: 0.5862032828739335\nEpoch 3/5, Validation Accuracy: 70.91%\nEpoch 4/5, Loss: 0.5756860149828769\nEpoch 4/5, Validation Accuracy: 69.25%\nEpoch 5/5, Loss: 0.5782379466855065\nEpoch 5/5, Validation Accuracy: 68.63%\nFold 3/3\nEpoch 1/5, Loss: 0.5775914977597927\nEpoch 1/5, Validation Accuracy: 71.12%\nEpoch 2/5, Loss: 0.570761593007251\nEpoch 2/5, Validation Accuracy: 69.18%\nEpoch 3/5, Loss: 0.5730874442922477\nEpoch 3/5, Validation Accuracy: 71.19%\nEpoch 4/5, Loss: 0.5682211310823978\nEpoch 4/5, Validation Accuracy: 70.08%\nEpoch 5/5, Loss: 0.5582303773632366\nEpoch 5/5, Validation Accuracy: 73.20%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 04:33:04,085] Trial 1 finished with value: 0.7024469067405356 and parameters: {'lr': 9.696843557773364e-05}. Best is trial 1 with value: 0.7024469067405356.\n<ipython-input-8-2e749100ab16>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Fold 1/3\nEpoch 1/5, Loss: 3.688293137603043\nEpoch 1/5, Validation Accuracy: 66.48%\nEpoch 2/5, Loss: 2.280350705207382\nEpoch 2/5, Validation Accuracy: 58.52%\nEpoch 3/5, Loss: 2.6602911414033144\nEpoch 3/5, Validation Accuracy: 51.59%\nEpoch 4/5, Loss: 3.1927455107151475\nEpoch 4/5, Validation Accuracy: 63.02%\nEpoch 5/5, Loss: 2.778517560734933\nEpoch 5/5, Validation Accuracy: 56.02%\nFold 2/3\nEpoch 1/5, Loss: 2.8221851956119854\nEpoch 1/5, Validation Accuracy: 60.53%\nEpoch 2/5, Loss: 2.5717420696553606\nEpoch 2/5, Validation Accuracy: 61.63%\nEpoch 3/5, Loss: 2.9839888508148613\nEpoch 3/5, Validation Accuracy: 59.97%\nEpoch 4/5, Loss: 2.4047709357672633\nEpoch 4/5, Validation Accuracy: 64.54%\nEpoch 5/5, Loss: 2.7693122272992\nEpoch 5/5, Validation Accuracy: 68.63%\nFold 3/3\nEpoch 1/5, Loss: 2.310459532955075\nEpoch 1/5, Validation Accuracy: 67.52%\nEpoch 2/5, Loss: 2.6355730016916494\nEpoch 2/5, Validation Accuracy: 63.57%\nEpoch 3/5, Loss: 2.8106772751439344\nEpoch 3/5, Validation Accuracy: 51.59%\nEpoch 4/5, Loss: 3.692889230685998\nEpoch 4/5, Validation Accuracy: 67.45%\nEpoch 5/5, Loss: 2.512515211302931\nEpoch 5/5, Validation Accuracy: 69.60%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 05:02:29,320] Trial 2 finished with value: 0.6389658356417359 and parameters: {'lr': 0.09272046781500869}. Best is trial 1 with value: 0.7024469067405356.\n<ipython-input-8-2e749100ab16>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Fold 1/3\nEpoch 1/5, Loss: 0.8806112818625751\nEpoch 1/5, Validation Accuracy: 65.44%\nEpoch 2/5, Loss: 0.8294349294670379\nEpoch 2/5, Validation Accuracy: 62.67%\nEpoch 3/5, Loss: 0.7460428286981846\nEpoch 3/5, Validation Accuracy: 67.87%\nEpoch 4/5, Loss: 0.8407730504623434\nEpoch 4/5, Validation Accuracy: 66.00%\nEpoch 5/5, Loss: 0.7996202468542762\nEpoch 5/5, Validation Accuracy: 64.68%\nFold 2/3\nEpoch 1/5, Loss: 0.8825977110401702\nEpoch 1/5, Validation Accuracy: 58.24%\nEpoch 2/5, Loss: 0.8711639869937581\nEpoch 2/5, Validation Accuracy: 70.22%\nEpoch 3/5, Loss: 0.8320537331354553\nEpoch 3/5, Validation Accuracy: 69.46%\nEpoch 4/5, Loss: 0.7756334072318525\nEpoch 4/5, Validation Accuracy: 70.50%\nEpoch 5/5, Loss: 0.7614442984372871\nEpoch 5/5, Validation Accuracy: 68.98%\nFold 3/3\nEpoch 1/5, Loss: 0.8091335044710676\nEpoch 1/5, Validation Accuracy: 72.37%\nEpoch 2/5, Loss: 0.8653986704283656\nEpoch 2/5, Validation Accuracy: 70.50%\nEpoch 3/5, Loss: 0.9008888831125439\nEpoch 3/5, Validation Accuracy: 68.91%\nEpoch 4/5, Loss: 0.9055204495211333\nEpoch 4/5, Validation Accuracy: 68.49%\nEpoch 5/5, Loss: 0.8849846524757575\nEpoch 5/5, Validation Accuracy: 70.91%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 05:32:06,462] Trial 3 finished with value: 0.677746999076639 and parameters: {'lr': 0.016711351365217328}. Best is trial 1 with value: 0.7024469067405356.\n<ipython-input-8-2e749100ab16>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Fold 1/3\nEpoch 1/5, Loss: 0.6864445453190672\nEpoch 1/5, Validation Accuracy: 62.95%\nEpoch 2/5, Loss: 0.6369747150668782\nEpoch 2/5, Validation Accuracy: 65.24%\nEpoch 3/5, Loss: 0.6216847922920522\nEpoch 3/5, Validation Accuracy: 67.24%\nEpoch 4/5, Loss: 0.6056085800268374\nEpoch 4/5, Validation Accuracy: 68.49%\nEpoch 5/5, Loss: 0.5905672417161214\nEpoch 5/5, Validation Accuracy: 67.45%\nFold 2/3\nEpoch 1/5, Loss: 0.5883290128813264\nEpoch 1/5, Validation Accuracy: 69.53%\nEpoch 2/5, Loss: 0.5836724711386538\nEpoch 2/5, Validation Accuracy: 70.91%\nEpoch 3/5, Loss: 0.5798054370432268\nEpoch 3/5, Validation Accuracy: 69.39%\nEpoch 4/5, Loss: 0.5720331683672594\nEpoch 4/5, Validation Accuracy: 69.39%\nEpoch 5/5, Loss: 0.5686594265929902\nEpoch 5/5, Validation Accuracy: 70.57%\nFold 3/3\nEpoch 1/5, Loss: 0.569178360601815\nEpoch 1/5, Validation Accuracy: 70.84%\nEpoch 2/5, Loss: 0.563130087450723\nEpoch 2/5, Validation Accuracy: 71.81%\nEpoch 3/5, Loss: 0.5607325036222763\nEpoch 3/5, Validation Accuracy: 72.09%\nEpoch 4/5, Loss: 0.5565325410326541\nEpoch 4/5, Validation Accuracy: 71.81%\nEpoch 5/5, Loss: 0.5509286333513523\nEpoch 5/5, Validation Accuracy: 71.75%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 06:01:51,635] Trial 4 finished with value: 0.713758079409049 and parameters: {'lr': 0.00015796033417859846}. Best is trial 4 with value: 0.713758079409049.\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Best Learning Rate for DENSENET121: 0.00015796033417859846\n\nEvaluating on Fold 1/3\nEpoch 1/5, Loss: 0.6648815860405811\nEpoch 1/5, Validation Accuracy: 63.50%\nEpoch 2/5, Loss: 0.6229810168071347\nEpoch 2/5, Validation Accuracy: 67.52%\nEpoch 3/5, Loss: 0.6050401977083301\nEpoch 3/5, Validation Accuracy: 66.41%\nEpoch 4/5, Loss: 0.585142982269519\nEpoch 4/5, Validation Accuracy: 68.77%\nEpoch 5/5, Loss: 0.5842451249038317\nEpoch 5/5, Validation Accuracy: 69.04%\n\nEvaluating on Fold 2/3\nEpoch 1/5, Loss: 0.5803197024606209\nEpoch 1/5, Validation Accuracy: 69.67%\nEpoch 2/5, Loss: 0.5809921628862454\nEpoch 2/5, Validation Accuracy: 70.43%\nEpoch 3/5, Loss: 0.5697306195346031\nEpoch 3/5, Validation Accuracy: 71.19%\nEpoch 4/5, Loss: 0.5631525946256205\nEpoch 4/5, Validation Accuracy: 70.71%\nEpoch 5/5, Loss: 0.5676288919224923\nEpoch 5/5, Validation Accuracy: 72.16%\n\nEvaluating on Fold 3/3\nEpoch 1/5, Loss: 0.5657112242767165\nEpoch 1/5, Validation Accuracy: 71.68%\nEpoch 2/5, Loss: 0.5637625612277353\nEpoch 2/5, Validation Accuracy: 72.02%\nEpoch 3/5, Loss: 0.5562793013140641\nEpoch 3/5, Validation Accuracy: 72.71%\nEpoch 4/5, Loss: 0.5558591163948755\nEpoch 4/5, Validation Accuracy: 72.37%\nEpoch 5/5, Loss: 0.5592205456936556\nEpoch 5/5, Validation Accuracy: 72.16%\nFold 1 Metrics:\nAccuracy: 0.69, Precision: 0.67, Recall: 0.72, F1-Score: 0.70\nConfusion Matrix:\n[[1208  633]\n [ 489 1279]]\nFold 2 Metrics:\nAccuracy: 0.71, Precision: 0.73, Recall: 0.67, F1-Score: 0.70\nConfusion Matrix:\n[[1351  456]\n [ 586 1216]]\nFold 3 Metrics:\nAccuracy: 0.72, Precision: 0.74, Recall: 0.69, F1-Score: 0.71\nConfusion Matrix:\n[[1306  459]\n [ 565 1278]]\n\nAverage Metrics Across Folds:\nAccuracy: 0.71, Precision: 0.71, Recall: 0.70, F1-Score: 0.70\nConfusion Matrix (sum of all folds):\n[[3865 1548]\n [1640 3773]]\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def initialize_model(name):\n    if model_name == \"densenet121\":\n        # Load DenseNet-121 without pre-trained weights (pretrained=False)\n        model = models.densenet121(pretrained=True)\n        \n        # Accessing the last two convolutional layers by their names\n        layer_list = list(model.features.children())  # Extract layers as a list\n        \n        # The last conv layers are within dense block 4's final part\n        last_conv_layer = layer_list[-1]  # Last layer is the final 1x1 convolution before the classifier\n        \n        # Unfreeze parameters of the last two conv layers\n        for param in last_conv_layer.parameters():\n            param.requires_grad = True\n\n        # Optionally, unfreeze the second last conv layer if needed\n        second_last_conv_layer = layer_list[-2]\n        for param in second_last_conv_layer.parameters():\n            param.requires_grad = True\n\n        # Modify the classifier to adjust for binary classification\n        model.classifier = nn.Sequential(\n            nn.Linear(model.classifier.in_features, 512),  # Reduce features from input size to 512\n            nn.ReLU(),\n            nn.Dropout(p=0.2),\n            nn.Linear(512, 2) \n        )\n\n        # Print the number of trainable parameters\n        def count_trainable_params(model):\n            return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n        print(f\"Total trainable parameters: {count_trainable_params(model):,}\")\n\n    else:\n        raise ValueError(f\"Model '{name}' is not supported. Only 'densenet121' is implemented.\")\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T18:22:32.201008Z","iopub.execute_input":"2024-12-25T18:22:32.201284Z","iopub.status.idle":"2024-12-25T18:22:32.207150Z","shell.execute_reply.started":"2024-12-25T18:22:32.201262Z","shell.execute_reply":"2024-12-25T18:22:32.206279Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# for fine tunning\ndef objective_after(trial, model_name):\n    # Get a suggested learning rate from Optuna\n    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n    \n    # Initialize the model with dropout\n    model = initialize_model(model_name).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    \n    val_accuracies = []\n    for fold_idx, (train_val_idx, test_idx) in enumerate(kf.split(dataset)):\n        print(f\"Fold {fold_idx + 1}/{num_folds}\")\n        \n        # Create training/validation split\n        train_val_data = Subset(dataset, train_val_idx)\n        test_data = Subset(dataset, test_idx)\n        \n        train_size = int(0.8 * len(train_val_data))\n        val_size = len(train_val_data) - train_size\n        train_data, val_data = torch.utils.data.random_split(\n            train_val_data, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n        )\n        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n        \n        # Train the model and get validation accuracy\n        train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)\n        \n        # Evaluate on validation set\n        val_accuracy, _, _, _, _ = calculate_metrics(model, val_loader, device)\n        val_accuracies.append(val_accuracy)\n    \n    # Return the average validation accuracy across all folds as the objective value\n    return np.mean(val_accuracies)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T18:22:34.981736Z","iopub.execute_input":"2024-12-25T18:22:34.982009Z","iopub.status.idle":"2024-12-25T18:22:34.988161Z","shell.execute_reply.started":"2024-12-25T18:22:34.981989Z","shell.execute_reply":"2024-12-25T18:22:34.987457Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"def evaluate_test(model_name, best_lr):\n    # Initialize model with the best learning rate\n    model = initialize_model(model_name).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=best_lr)\n    criterion = nn.CrossEntropyLoss()\n\n    fold_metrics = []\n    for fold_idx, (train_val_idx, test_idx) in enumerate(kf.split(dataset)):\n        print(f\"\\nEvaluating on Fold {fold_idx + 1}/{num_folds}\")\n        \n        # Create training/validation split\n        train_val_data = Subset(dataset, train_val_idx)\n        test_data = Subset(dataset, test_idx)\n        \n        train_size = int(0.8 * len(train_val_data))\n        val_size = len(train_val_data) - train_size\n        train_data, val_data = torch.utils.data.random_split(\n            train_val_data, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n        )\n        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n        \n        # Train the model\n        train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)\n        \n        # Evaluate on the test set\n        test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n        fold_metrics.append(calculate_metrics(model, test_loader, device))\n    \n    # Print metrics for each fold\n    for fold_idx, metrics in enumerate(fold_metrics):\n        accuracy, precision, recall, f1, conf_matrix = metrics\n        print(f\"Fold {fold_idx + 1} Metrics:\")\n        print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}\")\n        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n\n# Calculate average metrics across folds\n    avg_accuracy = np.mean([metrics[0] for metrics in fold_metrics])\n    avg_precision = np.mean([metrics[1] for metrics in fold_metrics])\n    avg_recall = np.mean([metrics[2] for metrics in fold_metrics])\n    avg_f1 = np.mean([metrics[3] for metrics in fold_metrics])\n    total_conf_matrix = np.sum([metrics[4] for metrics in fold_metrics], axis=0)\n\n    print(\"\\nAverage Metrics Across Folds:\")\n    print(f\"Accuracy: {avg_accuracy:.2f}, Precision: {avg_precision:.2f}, Recall: {avg_recall:.2f}, F1-Score: {avg_f1:.2f}\")\n    print(f\"Confusion Matrix (sum of all folds):\\n{total_conf_matrix}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T18:22:38.991836Z","iopub.execute_input":"2024-12-25T18:22:38.992149Z","iopub.status.idle":"2024-12-25T18:22:39.000595Z","shell.execute_reply.started":"2024-12-25T18:22:38.992118Z","shell.execute_reply":"2024-12-25T18:22:38.999691Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# Optuna Optimization and Final Testing\nfor model_name in [\"densenet121\"]:\n    print(f\"\\nOptimizing for {model_name.upper()}...\")\n    study = optuna.create_study(direction='maximize')\n    study.optimize(lambda trial: objective_after(trial, model_name), n_trials=5)  \n\n    # Best learning rate found for the model\n    best_lr = study.best_params['lr']\n    print(f\"Best Learning Rate for {model_name.upper()}: {best_lr}\")\n\n    # Evaluate on test sets for each fold\n    evaluate_test(model_name, best_lr)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T18:22:42.127894Z","iopub.execute_input":"2024-12-25T18:22:42.128163Z","iopub.status.idle":"2024-12-25T22:13:01.495916Z","shell.execute_reply.started":"2024-12-25T18:22:42.128142Z","shell.execute_reply":"2024-12-25T22:13:01.495154Z"}},"outputs":[{"name":"stderr","text":"[I 2024-12-25 18:22:42,129] A new study created in memory with name: no-name-eea36710-88de-435a-9939-8c573dae8663\n","output_type":"stream"},{"name":"stdout","text":"\nOptimizing for DENSENET121...\nTotal trainable parameters: 7,479,682\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-40-fd9538108a4f>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n","output_type":"stream"},{"name":"stdout","text":"Fold 1/3\nEpoch 1/5, Loss: 0.5811830647083935\nEpoch 1/5, Validation Accuracy: 59.49%\nEpoch 2/5, Loss: 0.4624601235376537\nEpoch 2/5, Validation Accuracy: 75.00%\nEpoch 3/5, Loss: 0.4187596277308069\nEpoch 3/5, Validation Accuracy: 79.09%\nEpoch 4/5, Loss: 0.40130866504176543\nEpoch 4/5, Validation Accuracy: 82.89%\nEpoch 5/5, Loss: 0.37205399161214986\nEpoch 5/5, Validation Accuracy: 82.27%\nFold 2/3\nEpoch 1/5, Loss: 0.3754355005137828\nEpoch 1/5, Validation Accuracy: 83.59%\nEpoch 2/5, Loss: 0.36511331434407945\nEpoch 2/5, Validation Accuracy: 75.48%\nEpoch 3/5, Loss: 0.35123563800727464\nEpoch 3/5, Validation Accuracy: 85.18%\nEpoch 4/5, Loss: 0.3325019691201205\nEpoch 4/5, Validation Accuracy: 85.04%\nEpoch 5/5, Loss: 0.3308088981973532\nEpoch 5/5, Validation Accuracy: 85.11%\nFold 3/3\nEpoch 1/5, Loss: 0.32436175208065393\nEpoch 1/5, Validation Accuracy: 86.43%\nEpoch 2/5, Loss: 0.3135527540307019\nEpoch 2/5, Validation Accuracy: 84.00%\nEpoch 3/5, Loss: 0.31170905109762487\nEpoch 3/5, Validation Accuracy: 84.56%\nEpoch 4/5, Loss: 0.2999251760665883\nEpoch 4/5, Validation Accuracy: 87.19%\nEpoch 5/5, Loss: 0.2880076030423628\nEpoch 5/5, Validation Accuracy: 87.40%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 19:00:58,193] Trial 0 finished with value: 0.8462603878116344 and parameters: {'lr': 0.0010218456511740415}. Best is trial 0 with value: 0.8462603878116344.\n<ipython-input-40-fd9538108a4f>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Total trainable parameters: 7,479,682\nFold 1/3\nEpoch 1/5, Loss: 0.8842553733462128\nEpoch 1/5, Validation Accuracy: 50.62%\nEpoch 2/5, Loss: 0.6937048557054931\nEpoch 2/5, Validation Accuracy: 49.38%\nEpoch 3/5, Loss: 0.6940120840599524\nEpoch 3/5, Validation Accuracy: 50.62%\nEpoch 4/5, Loss: 0.6933958438219945\nEpoch 4/5, Validation Accuracy: 50.62%\nEpoch 5/5, Loss: 0.6938816961003931\nEpoch 5/5, Validation Accuracy: 49.38%\nFold 2/3\nEpoch 1/5, Loss: 0.6938814919297867\nEpoch 1/5, Validation Accuracy: 50.00%\nEpoch 2/5, Loss: 0.6934685437060193\nEpoch 2/5, Validation Accuracy: 50.00%\nEpoch 3/5, Loss: 0.6941591287186133\nEpoch 3/5, Validation Accuracy: 50.00%\nEpoch 4/5, Loss: 0.6935472481817172\nEpoch 4/5, Validation Accuracy: 50.00%\nEpoch 5/5, Loss: 0.6933858954445433\nEpoch 5/5, Validation Accuracy: 50.00%\nFold 3/3\nEpoch 1/5, Loss: 0.693908724336993\nEpoch 1/5, Validation Accuracy: 51.59%\nEpoch 2/5, Loss: 0.6938630128433692\nEpoch 2/5, Validation Accuracy: 48.41%\nEpoch 3/5, Loss: 0.6935880338948076\nEpoch 3/5, Validation Accuracy: 51.59%\nEpoch 4/5, Loss: 0.6936787903638176\nEpoch 4/5, Validation Accuracy: 48.41%\nEpoch 5/5, Loss: 0.6933519613018352\nEpoch 5/5, Validation Accuracy: 51.59%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 19:38:43,664] Trial 1 finished with value: 0.5032317636195752 and parameters: {'lr': 0.011533934146830346}. Best is trial 0 with value: 0.8462603878116344.\n<ipython-input-40-fd9538108a4f>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Total trainable parameters: 7,479,682\nFold 1/3\nEpoch 1/5, Loss: 0.450519810723995\nEpoch 1/5, Validation Accuracy: 85.32%\nEpoch 2/5, Loss: 0.31272678517669605\nEpoch 2/5, Validation Accuracy: 85.87%\nEpoch 3/5, Loss: 0.26666142869720144\nEpoch 3/5, Validation Accuracy: 87.74%\nEpoch 4/5, Loss: 0.243565551895463\nEpoch 4/5, Validation Accuracy: 89.06%\nEpoch 5/5, Loss: 0.22316979616880417\nEpoch 5/5, Validation Accuracy: 89.75%\nFold 2/3\nEpoch 1/5, Loss: 0.22574586906979754\nEpoch 1/5, Validation Accuracy: 93.01%\nEpoch 2/5, Loss: 0.20883609568545833\nEpoch 2/5, Validation Accuracy: 91.14%\nEpoch 3/5, Loss: 0.18968658441502745\nEpoch 3/5, Validation Accuracy: 91.69%\nEpoch 4/5, Loss: 0.18962184739046992\nEpoch 4/5, Validation Accuracy: 92.73%\nEpoch 5/5, Loss: 0.1702009315154829\nEpoch 5/5, Validation Accuracy: 91.48%\nFold 3/3\nEpoch 1/5, Loss: 0.1956769665445906\nEpoch 1/5, Validation Accuracy: 92.04%\nEpoch 2/5, Loss: 0.17875257943298936\nEpoch 2/5, Validation Accuracy: 93.35%\nEpoch 3/5, Loss: 0.15824700988705645\nEpoch 3/5, Validation Accuracy: 89.82%\nEpoch 4/5, Loss: 0.16060821731569688\nEpoch 4/5, Validation Accuracy: 92.17%\nEpoch 5/5, Loss: 0.1473798697906963\nEpoch 5/5, Validation Accuracy: 93.14%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 20:17:05,755] Trial 2 finished with value: 0.9180517082179133 and parameters: {'lr': 9.020485241046237e-05}. Best is trial 2 with value: 0.9180517082179133.\n<ipython-input-40-fd9538108a4f>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Total trainable parameters: 7,479,682\nFold 1/3\nEpoch 1/5, Loss: 1.3106200879450003\nEpoch 1/5, Validation Accuracy: 49.38%\nEpoch 2/5, Loss: 0.6935215091837045\nEpoch 2/5, Validation Accuracy: 50.62%\nEpoch 3/5, Loss: 0.6938461371548268\nEpoch 3/5, Validation Accuracy: 50.62%\nEpoch 4/5, Loss: 0.694017800836932\nEpoch 4/5, Validation Accuracy: 49.38%\nEpoch 5/5, Validation Accuracy: 50.62%\nFold 2/3\nEpoch 1/5, Loss: 0.6940463056880466\nEpoch 1/5, Validation Accuracy: 50.00%\nEpoch 2/5, Loss: 0.694515637271312\nEpoch 2/5, Validation Accuracy: 50.00%\nEpoch 3/5, Loss: 0.6937158716976314\nEpoch 3/5, Validation Accuracy: 50.00%\nEpoch 4/5, Loss: 0.6950352547577073\nEpoch 4/5, Validation Accuracy: 50.00%\nEpoch 5/5, Loss: 0.6939180664594661\nEpoch 5/5, Validation Accuracy: 50.00%\nFold 3/3\nEpoch 1/5, Loss: 0.6938688804431515\nEpoch 1/5, Validation Accuracy: 48.41%\nEpoch 2/5, Loss: 0.6941283667943754\nEpoch 2/5, Validation Accuracy: 51.59%\nEpoch 3/5, Loss: 0.6932613326041079\nEpoch 3/5, Validation Accuracy: 51.59%\nEpoch 4/5, Loss: 0.6939151168528183\nEpoch 4/5, Validation Accuracy: 51.59%\nEpoch 5/5, Loss: 0.6943551295370028\nEpoch 5/5, Validation Accuracy: 51.59%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 20:54:46,318] Trial 3 finished with value: 0.5073868882733149 and parameters: {'lr': 0.020171740431524397}. Best is trial 2 with value: 0.9180517082179133.\n<ipython-input-40-fd9538108a4f>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Total trainable parameters: 7,479,682\nFold 1/3\nEpoch 1/5, Loss: 0.7189875620504769\nEpoch 1/5, Validation Accuracy: 51.18%\nEpoch 2/5, Loss: 0.6885512481078259\nEpoch 2/5, Validation Accuracy: 55.75%\nEpoch 3/5, Loss: 0.6881127551774293\nEpoch 3/5, Validation Accuracy: 51.66%\nEpoch 4/5, Loss: 0.6880653401764717\nEpoch 4/5, Validation Accuracy: 50.07%\nEpoch 5/5, Loss: 0.69197360059833\nEpoch 5/5, Validation Accuracy: 53.25%\nFold 2/3\nEpoch 1/5, Loss: 0.6919330292643763\nEpoch 1/5, Validation Accuracy: 57.69%\nEpoch 2/5, Loss: 0.6878300701057055\nEpoch 2/5, Validation Accuracy: 54.36%\nEpoch 3/5, Loss: 0.6886446996288405\nEpoch 3/5, Validation Accuracy: 58.59%\nEpoch 4/5, Loss: 0.6862459409961384\nEpoch 4/5, Validation Accuracy: 57.62%\nEpoch 5/5, Loss: 0.6870491310377806\nEpoch 5/5, Validation Accuracy: 58.17%\nFold 3/3\nEpoch 1/5, Loss: 0.690136407291033\nEpoch 1/5, Validation Accuracy: 55.54%\nEpoch 2/5, Loss: 0.6900319137625931\nEpoch 2/5, Validation Accuracy: 56.58%\nEpoch 3/5, Loss: 0.687779539197848\nEpoch 3/5, Validation Accuracy: 57.06%\nEpoch 4/5, Loss: 0.6830997335318044\nEpoch 4/5, Validation Accuracy: 56.86%\nEpoch 5/5, Loss: 0.6852788869188635\nEpoch 5/5, Validation Accuracy: 58.59%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 21:33:02,456] Trial 4 finished with value: 0.556555863342567 and parameters: {'lr': 0.002004817761946956}. Best is trial 2 with value: 0.9180517082179133.\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Best Learning Rate for DENSENET121: 9.020485241046237e-05\nTotal trainable parameters: 7,479,682\n\nEvaluating on Fold 1/3\nEpoch 1/5, Loss: 0.4564156552869312\nEpoch 1/5, Validation Accuracy: 84.14%\nEpoch 2/5, Loss: 0.32761735250936685\nEpoch 2/5, Validation Accuracy: 84.28%\nEpoch 3/5, Loss: 0.2730421853452427\nEpoch 3/5, Validation Accuracy: 87.47%\nEpoch 4/5, Loss: 0.24607015273518326\nEpoch 4/5, Validation Accuracy: 87.60%\nEpoch 5/5, Loss: 0.21116373607713873\nEpoch 5/5, Validation Accuracy: 89.61%\n\nEvaluating on Fold 2/3\nEpoch 1/5, Loss: 0.23535682623228316\nEpoch 1/5, Validation Accuracy: 91.97%\nEpoch 2/5, Loss: 0.21303271992101194\nEpoch 2/5, Validation Accuracy: 92.04%\nEpoch 3/5, Loss: 0.18131489430178596\nEpoch 3/5, Validation Accuracy: 91.62%\nEpoch 4/5, Loss: 0.1899389770519997\nEpoch 4/5, Validation Accuracy: 92.59%\nEpoch 5/5, Loss: 0.16710293000738924\nEpoch 5/5, Validation Accuracy: 91.00%\n\nEvaluating on Fold 3/3\nEpoch 1/5, Loss: 0.19069518445275765\nEpoch 1/5, Validation Accuracy: 92.52%\nEpoch 2/5, Loss: 0.1797420618674867\nEpoch 2/5, Validation Accuracy: 92.52%\nEpoch 3/5, Loss: 0.16157741673825854\nEpoch 3/5, Validation Accuracy: 92.45%\nEpoch 4/5, Loss: 0.15184130830412412\nEpoch 4/5, Validation Accuracy: 91.34%\nEpoch 5/5, Loss: 0.1500948941983406\nEpoch 5/5, Validation Accuracy: 91.48%\nFold 1 Metrics:\nAccuracy: 0.89, Precision: 0.90, Recall: 0.86, F1-Score: 0.88\nConfusion Matrix:\n[[1678  163]\n [ 243 1525]]\nFold 2 Metrics:\nAccuracy: 0.92, Precision: 0.94, Recall: 0.90, F1-Score: 0.92\nConfusion Matrix:\n[[1704  103]\n [ 187 1615]]\nFold 3 Metrics:\nAccuracy: 0.93, Precision: 0.95, Recall: 0.91, F1-Score: 0.93\nConfusion Matrix:\n[[1671   94]\n [ 158 1685]]\n\nAverage Metrics Across Folds:\nAccuracy: 0.91, Precision: 0.93, Recall: 0.89, F1-Score: 0.91\nConfusion Matrix (sum of all folds):\n[[5053  360]\n [ 588 4825]]\n","output_type":"stream"}],"execution_count":42}]}