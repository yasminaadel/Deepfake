{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10282316,"sourceType":"datasetVersion","datasetId":6363007}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom torchvision import transforms, models, datasets\nimport torch.optim as optim\nimport torch.nn as nn\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, precision_recall_fscore_support)\nfrom transformers import ViTForImageClassification, ViTFeatureExtractor\nimport optuna","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-25T13:35:01.662758Z","iopub.execute_input":"2024-12-25T13:35:01.663094Z","iopub.status.idle":"2024-12-25T13:35:10.927012Z","shell.execute_reply.started":"2024-12-25T13:35:01.663070Z","shell.execute_reply":"2024-12-25T13:35:10.926076Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"dataset_dir ='/kaggle/input/deepfake/DeepFake'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T13:35:16.150010Z","iopub.execute_input":"2024-12-25T13:35:16.150554Z","iopub.status.idle":"2024-12-25T13:35:16.154205Z","shell.execute_reply.started":"2024-12-25T13:35:16.150527Z","shell.execute_reply":"2024-12-25T13:35:16.153440Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"transform_train = transforms.Compose([\n    transforms.Resize((224, 224)),  \n    transforms.ToTensor(),  \n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(p=0.2),\n    transforms.RandomRotation(15),\n    transforms.RandomCrop(224, padding=10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.RandomAffine(degrees=20, scale=(0.8, 1.2), shear=10),\n    transforms.RandomErasing(p=0.3),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  \n])\n\ntransform_val_test = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T13:35:21.671046Z","iopub.execute_input":"2024-12-25T13:35:21.671357Z","iopub.status.idle":"2024-12-25T13:35:21.677599Z","shell.execute_reply.started":"2024-12-25T13:35:21.671331Z","shell.execute_reply":"2024-12-25T13:35:21.676685Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Load the dataset\nfrom torchvision.datasets import ImageFolder\ndataset = ImageFolder(root=dataset_dir, transform=transform_train)\nprint(\"Classes:\", dataset.classes)\nprint(\"Class-to-Index Mapping:\", dataset.class_to_idx)\nprint(\"Number of Samples:\", len(dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T13:35:34.398022Z","iopub.execute_input":"2024-12-25T13:35:34.398339Z","iopub.status.idle":"2024-12-25T13:35:57.854235Z","shell.execute_reply.started":"2024-12-25T13:35:34.398313Z","shell.execute_reply":"2024-12-25T13:35:57.853396Z"}},"outputs":[{"name":"stdout","text":"Classes: ['Fake', 'Real']\nClass-to-Index Mapping: {'Fake': 0, 'Real': 1}\nNumber of Samples: 10826\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def get_model(model_name):\n    if model_name == \"vgg-16\":\n        model = models.vgg16(pretrained=True)\n        \n        # Freeze the convolutional layers\n        for param in model.features.parameters():\n            param.requires_grad = False\n        \n        # Update the fully connected layer\n        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 2)  # Change the last layer to output 2 classes\n        return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T23:28:02.291428Z","iopub.execute_input":"2024-12-24T23:28:02.291716Z","iopub.status.idle":"2024-12-24T23:28:02.295990Z","shell.execute_reply.started":"2024-12-24T23:28:02.291693Z","shell.execute_reply":"2024-12-24T23:28:02.295108Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Calculate metrics function\ndef calculate_metrics(model, loader, device):\n    \n    # Set the model to evaluation mode (disables dropout)\n    model.eval()\n\n    # Lists to store true labels and predicted labels\n    all_labels = []\n    all_predictions = []\n\n    # Disabling gradient computation\n    with torch.no_grad():\n        for images, labels in loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n             # Get predicted labels by taking the argmax (most likely class)\n            _, predicted = torch.max(outputs, 1)\n            all_labels.extend(labels.cpu().numpy())\n            all_predictions.extend(predicted.cpu().numpy())\n\n     # Calculate the confusion matrix,which give TN, FP, FN, and TP\n    conf_matrix = confusion_matrix(all_labels, all_predictions)\n    # Unpack the confusion matrix into four components: TN, FP, FN, TP\n    TN, FP, FN, TP = conf_matrix.ravel() \n\n    total = conf_matrix.sum()\n    accuracy = (TP + TN) / total if total > 0 else 0.0\n    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n    \n    return accuracy, precision, recall, f1, conf_matrix\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T13:36:09.988842Z","iopub.execute_input":"2024-12-25T13:36:09.989152Z","iopub.status.idle":"2024-12-25T13:36:09.995496Z","shell.execute_reply.started":"2024-12-25T13:36:09.989130Z","shell.execute_reply":"2024-12-25T13:36:09.994664Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Train the model function with validation accuracy printed after each epoch\ndef train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5):\n    # Variable to track the best validation accuracy\n    best_val_accuracy = 0\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n         # Iterate over batches in the training data\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n        \n        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n        # Validation phase\n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        val_accuracy = 100 * correct / total\n        print(f\"Epoch {epoch+1}/{epochs}, Validation Accuracy: {val_accuracy:.2f}%\")\n        \n        if val_accuracy > best_val_accuracy:\n            best_val_accuracy = val_accuracy\n    \n    return best_val_accuracy\n\n# Device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Cross-validation setup\nnum_folds = 3\nkf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T13:36:20.479868Z","iopub.execute_input":"2024-12-25T13:36:20.480203Z","iopub.status.idle":"2024-12-25T13:36:20.558891Z","shell.execute_reply.started":"2024-12-25T13:36:20.480175Z","shell.execute_reply":"2024-12-25T13:36:20.557954Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def objective(trial, model_name):\n    # Get a suggested learning rate from Optuna\n    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n    \n    # Initialize the model with dropout\n    model = get_model(model_name).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    \n    val_accuracies = []\n    for fold_idx, (train_val_idx, test_idx) in enumerate(kf.split(dataset)):\n        print(f\"Fold {fold_idx + 1}/{num_folds}\")\n        \n        # Create training/validation split\n        train_val_data = Subset(dataset, train_val_idx)\n        test_data = Subset(dataset, test_idx)\n        \n        train_size = int(0.8 * len(train_val_data))\n        val_size = len(train_val_data) - train_size\n        train_data, val_data = torch.utils.data.random_split(\n            train_val_data, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n        )\n        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n        \n        # Train the model and get validation accuracy\n        train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)\n        \n        # Evaluate on validation set\n        val_accuracy, _, _, _, _ = calculate_metrics(model, val_loader, device)\n        val_accuracies.append(val_accuracy)\n    \n    # Return the average validation accuracy across all folds as the objective value\n    return np.mean(val_accuracies)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T23:28:19.767201Z","iopub.execute_input":"2024-12-24T23:28:19.767585Z","iopub.status.idle":"2024-12-24T23:28:19.775650Z","shell.execute_reply.started":"2024-12-24T23:28:19.767547Z","shell.execute_reply":"2024-12-24T23:28:19.774648Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def evaluate_test_set(model_name, best_lr):\n    # Initialize model with the best learning rate\n    model = get_model(model_name).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=best_lr)\n    criterion = nn.CrossEntropyLoss()\n\n    fold_metrics = []\n    for fold_idx, (train_val_idx, test_idx) in enumerate(kf.split(dataset)):\n        print(f\"\\nEvaluating on Fold {fold_idx + 1}/{num_folds}\")\n        \n        # Create training/validation split\n        train_val_data = Subset(dataset, train_val_idx)\n        test_data = Subset(dataset, test_idx)\n        \n        train_size = int(0.8 * len(train_val_data))\n        val_size = len(train_val_data) - train_size\n        train_data, val_data = torch.utils.data.random_split(\n            train_val_data, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n        )\n        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n        \n        # Train the model\n        train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)\n        \n        # Evaluate on the test set\n        test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n        fold_metrics.append(calculate_metrics(model, test_loader, device))\n    \n    # Print metrics for each fold\n    for fold_idx, metrics in enumerate(fold_metrics):\n        accuracy, precision, recall, f1, conf_matrix = metrics\n        print(f\"Fold {fold_idx + 1} Metrics:\")\n        print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}\")\n        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n\n# Calculate average metrics across folds\n    avg_accuracy = np.mean([metrics[0] for metrics in fold_metrics])\n    avg_precision = np.mean([metrics[1] for metrics in fold_metrics])\n    avg_recall = np.mean([metrics[2] for metrics in fold_metrics])\n    avg_f1 = np.mean([metrics[3] for metrics in fold_metrics])\n    total_conf_matrix = np.sum([metrics[4] for metrics in fold_metrics], axis=0)\n\n    print(\"\\nAverage Metrics Across Folds:\")\n    print(f\"Accuracy: {avg_accuracy:.2f}, Precision: {avg_precision:.2f}, Recall: {avg_recall:.2f}, F1-Score: {avg_f1:.2f}\")\n    print(f\"Confusion Matrix (sum of all folds):\\n{total_conf_matrix}\")\n\n\n# Optuna Optimization and Final Testing\nfor model_name in [ \"vgg-16\"]:\n    print(f\"\\nOptimizing for {model_name.upper()}...\")\n    study = optuna.create_study(direction='maximize')\n    study.optimize(lambda trial: objective(trial, model_name), n_trials=5)  # You can increase the number of trials if needed\n\n    # Best learning rate found for the model\n    best_lr = study.best_params['lr']\n    print(f\"Best Learning Rate for {model_name.upper()}: {best_lr}\")\n\n    # Evaluate on test sets for each fold\n    evaluate_test_set(model_name, best_lr)\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T23:31:29.641945Z","iopub.execute_input":"2024-12-24T23:31:29.642326Z","iopub.status.idle":"2024-12-25T03:01:27.743143Z","shell.execute_reply.started":"2024-12-24T23:31:29.642299Z","shell.execute_reply":"2024-12-25T03:01:27.741939Z"}},"outputs":[{"name":"stderr","text":"[I 2024-12-24 23:31:29,649] A new study created in memory with name: no-name-c1a28ac1-39ce-45cd-b81c-9f92ab264b9f\n","output_type":"stream"},{"name":"stdout","text":"\nOptimizing for VGG-16...\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-9-2e749100ab16>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|██████████| 528M/528M [00:02<00:00, 191MB/s]  \n","output_type":"stream"},{"name":"stdout","text":"Fold 1/3\nEpoch 1/5, Loss: 0.6363204455836702\nEpoch 1/5, Validation Accuracy: 64.13%\nEpoch 2/5, Loss: 0.5689530168449023\nEpoch 2/5, Validation Accuracy: 69.74%\nEpoch 3/5, Loss: 0.5611183839278985\nEpoch 3/5, Validation Accuracy: 73.34%\nEpoch 4/5, Loss: 0.5333395475182086\nEpoch 4/5, Validation Accuracy: 67.87%\nEpoch 5/5, Loss: 0.5253075162020836\nEpoch 5/5, Validation Accuracy: 72.78%\nFold 2/3\nEpoch 1/5, Loss: 0.5215318700226631\nEpoch 1/5, Validation Accuracy: 75.28%\nEpoch 2/5, Loss: 0.516530220844469\nEpoch 2/5, Validation Accuracy: 70.91%\nEpoch 3/5, Loss: 0.5123764760586438\nEpoch 3/5, Validation Accuracy: 74.79%\nEpoch 4/5, Loss: 0.5014847739296064\nEpoch 4/5, Validation Accuracy: 76.11%\nEpoch 5/5, Loss: 0.4950379110172967\nEpoch 5/5, Validation Accuracy: 76.04%\nFold 3/3\nEpoch 1/5, Loss: 0.4976999944086233\nEpoch 1/5, Validation Accuracy: 75.28%\nEpoch 2/5, Loss: 0.4962606650689689\nEpoch 2/5, Validation Accuracy: 77.15%\nEpoch 3/5, Loss: 0.4886985241708176\nEpoch 3/5, Validation Accuracy: 75.62%\nEpoch 4/5, Loss: 0.48760039239957187\nEpoch 4/5, Validation Accuracy: 76.04%\nEpoch 5/5, Loss: 0.4816086531014732\nEpoch 5/5, Validation Accuracy: 75.83%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 00:06:48,226] Trial 0 finished with value: 0.76061865189289 and parameters: {'lr': 0.00023232414378777328}. Best is trial 0 with value: 0.76061865189289.\n<ipython-input-9-2e749100ab16>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Fold 1/3\nEpoch 1/5, Loss: 0.6111141978377137\nEpoch 1/5, Validation Accuracy: 68.07%\nEpoch 2/5, Loss: 0.5565213200466409\nEpoch 2/5, Validation Accuracy: 68.49%\nEpoch 3/5, Loss: 0.5379496435763428\nEpoch 3/5, Validation Accuracy: 73.96%\nEpoch 4/5, Loss: 0.5389114980539564\nEpoch 4/5, Validation Accuracy: 72.51%\nEpoch 5/5, Loss: 0.5163992618658266\nEpoch 5/5, Validation Accuracy: 74.10%\nFold 2/3\nEpoch 1/5, Loss: 0.5119665502184663\nEpoch 1/5, Validation Accuracy: 74.45%\nEpoch 2/5, Loss: 0.508253854941268\nEpoch 2/5, Validation Accuracy: 73.41%\nEpoch 3/5, Loss: 0.4992490787861755\nEpoch 3/5, Validation Accuracy: 75.00%\nEpoch 4/5, Loss: 0.4892100295803165\nEpoch 4/5, Validation Accuracy: 76.32%\nEpoch 5/5, Loss: 0.4992637978403608\nEpoch 5/5, Validation Accuracy: 75.42%\nFold 3/3\nEpoch 1/5, Loss: 0.48951896728731653\nEpoch 1/5, Validation Accuracy: 76.32%\nEpoch 2/5, Loss: 0.4828535632863229\nEpoch 2/5, Validation Accuracy: 75.76%\nEpoch 3/5, Loss: 0.4803842446916011\nEpoch 3/5, Validation Accuracy: 77.22%\nEpoch 4/5, Loss: 0.4746125611317092\nEpoch 4/5, Validation Accuracy: 76.11%\nEpoch 5/5, Loss: 0.4584678977892544\nEpoch 5/5, Validation Accuracy: 77.15%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 00:41:26,280] Trial 1 finished with value: 0.7483841181902123 and parameters: {'lr': 5.726534038095225e-05}. Best is trial 0 with value: 0.76061865189289.\n<ipython-input-9-2e749100ab16>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Fold 1/3\nEpoch 1/5, Loss: 18.72678158559852\nEpoch 1/5, Validation Accuracy: 55.96%\nEpoch 2/5, Loss: 1.2284466067730393\nEpoch 2/5, Validation Accuracy: 50.69%\nEpoch 3/5, Loss: 1.109176668343623\nEpoch 3/5, Validation Accuracy: 51.45%\nEpoch 4/5, Loss: 0.9401237658374217\nEpoch 4/5, Validation Accuracy: 47.78%\nEpoch 5/5, Loss: 0.8581579436254765\nEpoch 5/5, Validation Accuracy: 50.48%\nFold 2/3\nEpoch 1/5, Loss: 0.7788878511328724\nEpoch 1/5, Validation Accuracy: 50.00%\nEpoch 2/5, Loss: 0.7467832183310998\nEpoch 2/5, Validation Accuracy: 50.14%\nEpoch 3/5, Loss: 0.8951938125968638\nEpoch 3/5, Validation Accuracy: 50.07%\nEpoch 4/5, Loss: 0.933921302221098\nEpoch 4/5, Validation Accuracy: 50.28%\nEpoch 5/5, Loss: 0.7120430881147226\nEpoch 5/5, Validation Accuracy: 50.00%\nFold 3/3\nEpoch 1/5, Loss: 0.8993786444980136\nEpoch 1/5, Validation Accuracy: 51.73%\nEpoch 2/5, Loss: 0.7403855748598088\nEpoch 2/5, Validation Accuracy: 51.52%\nEpoch 3/5, Loss: 0.7843927915583658\nEpoch 3/5, Validation Accuracy: 48.41%\nEpoch 4/5, Loss: 0.729899083382517\nEpoch 4/5, Validation Accuracy: 48.34%\nEpoch 5/5, Loss: 0.9976449776749584\nEpoch 5/5, Validation Accuracy: 48.34%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 01:15:57,201] Trial 2 finished with value: 0.4951523545706371 and parameters: {'lr': 0.006595530854826914}. Best is trial 0 with value: 0.76061865189289.\n<ipython-input-9-2e749100ab16>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Fold 1/3\nEpoch 1/5, Loss: 0.6318017502845321\nEpoch 1/5, Validation Accuracy: 67.04%\nEpoch 2/5, Loss: 0.5685112212902933\nEpoch 2/5, Validation Accuracy: 71.54%\nEpoch 3/5, Loss: 0.5407860717062134\nEpoch 3/5, Validation Accuracy: 71.26%\nEpoch 4/5, Loss: 0.5341001719401027\nEpoch 4/5, Validation Accuracy: 71.47%\nEpoch 5/5, Loss: 0.5236142284303739\nEpoch 5/5, Validation Accuracy: 73.34%\nFold 2/3\nEpoch 1/5, Loss: 0.5265970475436574\nEpoch 1/5, Validation Accuracy: 74.24%\nEpoch 2/5, Loss: 0.5174212459042586\nEpoch 2/5, Validation Accuracy: 75.21%\nEpoch 3/5, Loss: 0.49024172596509946\nEpoch 3/5, Validation Accuracy: 76.11%\nEpoch 4/5, Loss: 0.5012418575049764\nEpoch 4/5, Validation Accuracy: 77.49%\nEpoch 5/5, Loss: 0.49550394326942404\nEpoch 5/5, Validation Accuracy: 75.07%\nFold 3/3\nEpoch 1/5, Loss: 0.4893156334510824\nEpoch 1/5, Validation Accuracy: 77.08%\nEpoch 2/5, Loss: 0.49061598517618127\nEpoch 2/5, Validation Accuracy: 73.13%\nEpoch 3/5, Loss: 0.4954683405259696\nEpoch 3/5, Validation Accuracy: 78.88%\nEpoch 4/5, Loss: 0.4779164814158698\nEpoch 4/5, Validation Accuracy: 76.04%\nEpoch 5/5, Loss: 0.4848481133497881\nEpoch 5/5, Validation Accuracy: 76.04%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 01:50:24,682] Trial 3 finished with value: 0.7479224376731302 and parameters: {'lr': 0.00018454251688395138}. Best is trial 0 with value: 0.76061865189289.\n<ipython-input-9-2e749100ab16>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Fold 1/3\nEpoch 1/5, Loss: 0.7465211078936224\nEpoch 1/5, Validation Accuracy: 67.24%\nEpoch 2/5, Loss: 0.7070373435046792\nEpoch 2/5, Validation Accuracy: 54.85%\nEpoch 3/5, Loss: 0.6848726182023465\nEpoch 3/5, Validation Accuracy: 69.88%\nEpoch 4/5, Loss: 0.6488507241833934\nEpoch 4/5, Validation Accuracy: 72.44%\nEpoch 5/5, Loss: 0.6311506630636711\nEpoch 5/5, Validation Accuracy: 69.46%\nFold 2/3\nEpoch 1/5, Loss: 0.6180676541275741\nEpoch 1/5, Validation Accuracy: 72.58%\nEpoch 2/5, Loss: 0.6055443578332828\nEpoch 2/5, Validation Accuracy: 74.52%\nEpoch 3/5, Loss: 0.6045829059340019\nEpoch 3/5, Validation Accuracy: 73.13%\nEpoch 4/5, Loss: 0.6219024468851353\nEpoch 4/5, Validation Accuracy: 71.81%\nEpoch 5/5, Loss: 0.6032846448171204\nEpoch 5/5, Validation Accuracy: 73.68%\nFold 3/3\nEpoch 1/5, Loss: 0.6100661316629272\nEpoch 1/5, Validation Accuracy: 74.17%\nEpoch 2/5, Loss: 0.5856962656777208\nEpoch 2/5, Validation Accuracy: 73.34%\nEpoch 3/5, Loss: 0.5889473035519953\nEpoch 3/5, Validation Accuracy: 75.00%\nEpoch 4/5, Loss: 0.5876050426815096\nEpoch 4/5, Validation Accuracy: 75.69%\nEpoch 5/5, Loss: 0.5902483423770462\nEpoch 5/5, Validation Accuracy: 71.95%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 02:24:54,164] Trial 4 finished with value: 0.7326869806094183 and parameters: {'lr': 0.0009801144162306348}. Best is trial 0 with value: 0.76061865189289.\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Best Learning Rate for VGG-16: 0.00023232414378777328\n\nEvaluating on Fold 1/3\nEpoch 1/5, Loss: 0.6319872705646641\nEpoch 1/5, Validation Accuracy: 68.49%\nEpoch 2/5, Loss: 0.5780117880573589\nEpoch 2/5, Validation Accuracy: 72.51%\nEpoch 3/5, Loss: 0.5434516859318012\nEpoch 3/5, Validation Accuracy: 72.44%\nEpoch 4/5, Loss: 0.5358109084776094\nEpoch 4/5, Validation Accuracy: 69.53%\nEpoch 5/5, Loss: 0.5218565422856347\nEpoch 5/5, Validation Accuracy: 71.54%\n\nEvaluating on Fold 2/3\nEpoch 1/5, Loss: 0.523648278653951\nEpoch 1/5, Validation Accuracy: 75.83%\nEpoch 2/5, Loss: 0.513523651914702\nEpoch 2/5, Validation Accuracy: 75.83%\nEpoch 3/5, Loss: 0.5125458039631501\nEpoch 3/5, Validation Accuracy: 77.08%\nEpoch 4/5, Loss: 0.4979021134297492\nEpoch 4/5, Validation Accuracy: 73.48%\nEpoch 5/5, Loss: 0.489788967107541\nEpoch 5/5, Validation Accuracy: 75.35%\n\nEvaluating on Fold 3/3\nEpoch 1/5, Loss: 0.5019226293208191\nEpoch 1/5, Validation Accuracy: 75.69%\nEpoch 2/5, Loss: 0.5059820127092014\nEpoch 2/5, Validation Accuracy: 75.28%\nEpoch 3/5, Loss: 0.49508575576445013\nEpoch 3/5, Validation Accuracy: 74.65%\nEpoch 4/5, Loss: 0.4844704567562809\nEpoch 4/5, Validation Accuracy: 75.76%\nEpoch 5/5, Loss: 0.48721641063360877\nEpoch 5/5, Validation Accuracy: 73.89%\nFold 1 Metrics:\nAccuracy: 0.73, Precision: 0.79, Recall: 0.62, F1-Score: 0.69\nConfusion Matrix:\n[[1548  293]\n [ 671 1097]]\nFold 2 Metrics:\nAccuracy: 0.75, Precision: 0.71, Recall: 0.84, F1-Score: 0.77\nConfusion Matrix:\n[[1188  619]\n [ 285 1517]]\nFold 3 Metrics:\nAccuracy: 0.76, Precision: 0.70, Recall: 0.92, F1-Score: 0.80\nConfusion Matrix:\n[[1050  715]\n [ 153 1690]]\n\nAverage Metrics Across Folds:\nAccuracy: 0.75, Precision: 0.73, Recall: 0.79, F1-Score: 0.75\nConfusion Matrix (sum of all folds):\n[[3786 1627]\n [1109 4304]]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models\n\ndef initialize_model(name):\n    if name == \"vgg-16\":\n        model = models.vgg16(pretrained=True)\n\n        # Freeze all layers initially\n        for param in model.parameters():\n            param.requires_grad = False\n\n        # Unfreeze the last convolutional block\n        for param in model.features[24:].parameters():\n            param.requires_grad = True\n\n        # Modify the classifier for binary classification\n        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 2)\n\n        # Print trainable parameters\n        def count_trainable_params(model):\n            return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n        print(f\"Total trainable parameters: {count_trainable_params(model):,}\")\n\n    else:\n        raise ValueError(\"Model name must be 'vgg16'\")\n\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T13:36:35.729509Z","iopub.execute_input":"2024-12-25T13:36:35.729850Z","iopub.status.idle":"2024-12-25T13:36:35.735527Z","shell.execute_reply.started":"2024-12-25T13:36:35.729821Z","shell.execute_reply":"2024-12-25T13:36:35.734665Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# for fine tunning\ndef objective(trial, model_name):\n    # Get a suggested learning rate from Optuna\n    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n    \n    # Initialize the model with dropout\n    model = initialize_model(model_name).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    \n    val_accuracies = []\n    for fold_idx, (train_val_idx, test_idx) in enumerate(kf.split(dataset)):\n        print(f\"Fold {fold_idx + 1}/{num_folds}\")\n        \n        # Create training/validation split\n        train_val_data = Subset(dataset, train_val_idx)\n        test_data = Subset(dataset, test_idx)\n        \n        train_size = int(0.8 * len(train_val_data))\n        val_size = len(train_val_data) - train_size\n        train_data, val_data = torch.utils.data.random_split(\n            train_val_data, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n        )\n        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n        \n        # Train the model and get validation accuracy\n        train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)\n        \n        # Evaluate on validation set\n        val_accuracy, _, _, _, _ = calculate_metrics(model, val_loader, device)\n        val_accuracies.append(val_accuracy)\n    \n    # Return the average validation accuracy across all folds as the objective value\n    return np.mean(val_accuracies)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T13:36:41.583269Z","iopub.execute_input":"2024-12-25T13:36:41.583557Z","iopub.status.idle":"2024-12-25T13:36:41.590103Z","shell.execute_reply.started":"2024-12-25T13:36:41.583528Z","shell.execute_reply":"2024-12-25T13:36:41.589120Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def evaluate_test_set(model_name, best_lr):\n    # Initialize model with the best learning rate\n    model = initialize_model(model_name).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=best_lr)\n    criterion = nn.CrossEntropyLoss()\n\n    fold_metrics = []\n    for fold_idx, (train_val_idx, test_idx) in enumerate(kf.split(dataset)):\n        print(f\"\\nEvaluating on Fold {fold_idx + 1}/{num_folds}\")\n        \n        # Create training/validation split\n        train_val_data = Subset(dataset, train_val_idx)\n        test_data = Subset(dataset, test_idx)\n        \n        train_size = int(0.8 * len(train_val_data))\n        val_size = len(train_val_data) - train_size\n        train_data, val_data = torch.utils.data.random_split(\n            train_val_data, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n        )\n        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n        \n        # Train the model\n        train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)\n        \n        # Evaluate on the test set\n        test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n        fold_metrics.append(calculate_metrics(model, test_loader, device))\n    \n    # Print metrics for each fold\n    for fold_idx, metrics in enumerate(fold_metrics):\n        accuracy, precision, recall, f1, conf_matrix = metrics\n        print(f\"Fold {fold_idx + 1} Metrics:\")\n        print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}\")\n        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n\n# Calculate average metrics across folds\n    avg_accuracy = np.mean([metrics[0] for metrics in fold_metrics])\n    avg_precision = np.mean([metrics[1] for metrics in fold_metrics])\n    avg_recall = np.mean([metrics[2] for metrics in fold_metrics])\n    avg_f1 = np.mean([metrics[3] for metrics in fold_metrics])\n    total_conf_matrix = np.sum([metrics[4] for metrics in fold_metrics], axis=0)\n\n    print(\"\\nAverage Metrics Across Folds:\")\n    print(f\"Accuracy: {avg_accuracy:.2f}, Precision: {avg_precision:.2f}, Recall: {avg_recall:.2f}, F1-Score: {avg_f1:.2f}\")\n    print(f\"Confusion Matrix (sum of all folds):\\n{total_conf_matrix}\")\n\n\n# Optuna Optimization and Final Testing\nfor model_name in [ \"vgg-16\"]:\n    print(f\"\\nOptimizing for {model_name.upper()}...\")\n    study = optuna.create_study(direction='maximize')\n    study.optimize(lambda trial: objective(trial, model_name), n_trials=5)  # You can increase the number of trials if needed\n\n    # Best learning rate found for the model\n    best_lr = study.best_params['lr']\n    print(f\"Best Learning Rate for {model_name.upper()}: {best_lr}\")\n\n    # Evaluate on test sets for each fold\n    evaluate_test_set(model_name, best_lr)\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T13:36:47.035430Z","iopub.execute_input":"2024-12-25T13:36:47.035756Z","iopub.status.idle":"2024-12-25T17:14:29.609672Z","shell.execute_reply.started":"2024-12-25T13:36:47.035726Z","shell.execute_reply":"2024-12-25T17:14:29.608931Z"}},"outputs":[{"name":"stderr","text":"[I 2024-12-25 13:36:47,042] A new study created in memory with name: no-name-17b0a0f1-9a96-4029-a6ca-5a8d6ab07448\n","output_type":"stream"},{"name":"stdout","text":"\nOptimizing for VGG-16...\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-12-1c309b109a5c>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|██████████| 528M/528M [00:02<00:00, 201MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Total trainable parameters: 7,087,618\nFold 1/3\nEpoch 1/5, Loss: 0.5766741253065141\nEpoch 1/5, Validation Accuracy: 74.58%\nEpoch 2/5, Loss: 0.47229872503991943\nEpoch 2/5, Validation Accuracy: 75.14%\nEpoch 3/5, Loss: 0.436988354881824\nEpoch 3/5, Validation Accuracy: 78.32%\nEpoch 4/5, Loss: 0.4024952099303514\nEpoch 4/5, Validation Accuracy: 81.58%\nEpoch 5/5, Loss: 0.3973448743313057\nEpoch 5/5, Validation Accuracy: 82.69%\nFold 2/3\nEpoch 1/5, Loss: 0.3938990489718664\nEpoch 1/5, Validation Accuracy: 83.24%\nEpoch 2/5, Loss: 0.3623178517291559\nEpoch 2/5, Validation Accuracy: 82.55%\nEpoch 3/5, Loss: 0.3472687445622123\nEpoch 3/5, Validation Accuracy: 84.49%\nEpoch 4/5, Loss: 0.33660881986934177\nEpoch 4/5, Validation Accuracy: 84.35%\nEpoch 5/5, Loss: 0.3235711974827624\nEpoch 5/5, Validation Accuracy: 83.31%\nFold 3/3\nEpoch 1/5, Loss: 0.34186439623654874\nEpoch 1/5, Validation Accuracy: 85.04%\nEpoch 2/5, Loss: 0.31723081431665473\nEpoch 2/5, Validation Accuracy: 85.18%\nEpoch 3/5, Loss: 0.30455345047112986\nEpoch 3/5, Validation Accuracy: 83.59%\nEpoch 4/5, Loss: 0.3058612789156029\nEpoch 4/5, Validation Accuracy: 84.21%\nEpoch 5/5, Loss: 0.295493981435648\nEpoch 5/5, Validation Accuracy: 83.86%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 14:13:50,200] Trial 0 finished with value: 0.8331024930747922 and parameters: {'lr': 0.00010837400852480871}. Best is trial 0 with value: 0.8331024930747922.\n<ipython-input-12-1c309b109a5c>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Total trainable parameters: 7,087,618\nFold 1/3\nEpoch 1/5, Loss: 0.6308643398034638\nEpoch 1/5, Validation Accuracy: 74.10%\nEpoch 2/5, Loss: 0.5238915280083924\nEpoch 2/5, Validation Accuracy: 72.02%\nEpoch 3/5, Loss: 0.4989878061067992\nEpoch 3/5, Validation Accuracy: 75.97%\nEpoch 4/5, Loss: 0.44758592644778405\nEpoch 4/5, Validation Accuracy: 76.04%\nEpoch 5/5, Loss: 0.4302318046764774\nEpoch 5/5, Validation Accuracy: 79.36%\nFold 2/3\nEpoch 1/5, Loss: 0.43717797948510606\nEpoch 1/5, Validation Accuracy: 81.16%\nEpoch 2/5, Loss: 0.4134113563029147\nEpoch 2/5, Validation Accuracy: 81.37%\nEpoch 3/5, Loss: 0.4042451879760837\nEpoch 3/5, Validation Accuracy: 82.76%\nEpoch 4/5, Loss: 0.38456060132269043\nEpoch 4/5, Validation Accuracy: 83.45%\nEpoch 5/5, Loss: 0.3773757913329983\nEpoch 5/5, Validation Accuracy: 80.26%\nFold 3/3\nEpoch 1/5, Loss: 0.3759244882928732\nEpoch 1/5, Validation Accuracy: 84.21%\nEpoch 2/5, Loss: 0.35604010065451513\nEpoch 2/5, Validation Accuracy: 81.65%\nEpoch 3/5, Loss: 0.3478640214596664\nEpoch 3/5, Validation Accuracy: 84.00%\nEpoch 4/5, Loss: 0.3416368488778067\nEpoch 4/5, Validation Accuracy: 85.53%\nEpoch 5/5, Loss: 0.3278386863720351\nEpoch 5/5, Validation Accuracy: 83.52%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 14:50:10,487] Trial 1 finished with value: 0.8074792243767313 and parameters: {'lr': 0.0008719643260051275}. Best is trial 0 with value: 0.8331024930747922.\n<ipython-input-12-1c309b109a5c>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Total trainable parameters: 7,087,618\nFold 1/3\nEpoch 1/5, Loss: 25350.999267453975\nEpoch 1/5, Validation Accuracy: 49.45%\nEpoch 2/5, Loss: 31.196256118255427\nEpoch 2/5, Validation Accuracy: 49.38%\nEpoch 3/5, Loss: 10.937753267051107\nEpoch 3/5, Validation Accuracy: 49.52%\nEpoch 4/5, Loss: 2.1416879763919345\nEpoch 4/5, Validation Accuracy: 49.38%\nEpoch 5/5, Loss: 77.2609760540625\nEpoch 5/5, Validation Accuracy: 50.62%\nFold 2/3\nEpoch 1/5, Loss: 139.50489621794685\nEpoch 1/5, Validation Accuracy: 50.00%\nEpoch 2/5, Loss: 4.956349624125338\nEpoch 2/5, Validation Accuracy: 50.00%\nEpoch 3/5, Loss: 1.550271016787429\nEpoch 3/5, Validation Accuracy: 50.07%\nEpoch 4/5, Loss: 1.3982923900224886\nEpoch 4/5, Validation Accuracy: 50.07%\nEpoch 5/5, Loss: 1.4230551867853871\nEpoch 5/5, Validation Accuracy: 50.00%\nFold 3/3\nEpoch 1/5, Loss: 535.4179765921272\nEpoch 1/5, Validation Accuracy: 48.41%\nEpoch 2/5, Loss: 1.5920026137683931\nEpoch 2/5, Validation Accuracy: 48.41%\nEpoch 3/5, Loss: 1.6293043267002423\nEpoch 3/5, Validation Accuracy: 51.59%\nEpoch 4/5, Loss: 5.318769765822268\nEpoch 4/5, Validation Accuracy: 51.59%\nEpoch 5/5, Loss: 1.7339593537604612\nEpoch 5/5, Validation Accuracy: 51.59%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 15:26:20,068] Trial 2 finished with value: 0.5076177285318559 and parameters: {'lr': 0.09815321097808699}. Best is trial 0 with value: 0.8331024930747922.\n<ipython-input-12-1c309b109a5c>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Total trainable parameters: 7,087,618\nFold 1/3\nEpoch 1/5, Loss: 1.125412908542222\nEpoch 1/5, Validation Accuracy: 63.78%\nEpoch 2/5, Loss: 0.6066299257028168\nEpoch 2/5, Validation Accuracy: 74.79%\nEpoch 3/5, Loss: 0.5465516787207587\nEpoch 3/5, Validation Accuracy: 76.39%\nEpoch 4/5, Loss: 0.49954844887744\nEpoch 4/5, Validation Accuracy: 75.00%\nEpoch 5/5, Loss: 0.48699353643543813\nEpoch 5/5, Validation Accuracy: 78.88%\nFold 2/3\nEpoch 1/5, Loss: 0.4640914455303171\nEpoch 1/5, Validation Accuracy: 78.95%\nEpoch 2/5, Loss: 0.44638792676490974\nEpoch 2/5, Validation Accuracy: 79.99%\nEpoch 3/5, Loss: 0.44498560178345736\nEpoch 3/5, Validation Accuracy: 79.29%\nEpoch 4/5, Loss: 0.4389144851522551\nEpoch 4/5, Validation Accuracy: 81.23%\nEpoch 5/5, Loss: 0.46077225995327226\nEpoch 5/5, Validation Accuracy: 65.24%\nFold 3/3\nEpoch 1/5, Loss: 0.4784979752743442\nEpoch 1/5, Validation Accuracy: 80.26%\nEpoch 2/5, Loss: 0.4096433665212347\nEpoch 2/5, Validation Accuracy: 80.19%\nEpoch 3/5, Loss: 0.416691598230304\nEpoch 3/5, Validation Accuracy: 82.20%\nEpoch 4/5, Loss: 0.43983516138232215\nEpoch 4/5, Validation Accuracy: 79.92%\nEpoch 5/5, Loss: 0.4047729414964908\nEpoch 5/5, Validation Accuracy: 79.99%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 16:02:30,631] Trial 3 finished with value: 0.7469990766389657 and parameters: {'lr': 0.0033356263825548888}. Best is trial 0 with value: 0.8331024930747922.\n<ipython-input-12-1c309b109a5c>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Total trainable parameters: 7,087,618\nFold 1/3\nEpoch 1/5, Loss: 8.163281998252343\nEpoch 1/5, Validation Accuracy: 51.39%\nEpoch 2/5, Loss: 1.890694885293423\nEpoch 2/5, Validation Accuracy: 49.38%\nEpoch 3/5, Loss: 0.7053680736057008\nEpoch 3/5, Validation Accuracy: 50.48%\nEpoch 4/5, Loss: 0.700878318172792\nEpoch 4/5, Validation Accuracy: 49.38%\nEpoch 5/5, Loss: 0.6984701215891548\nEpoch 5/5, Validation Accuracy: 50.62%\nFold 2/3\nEpoch 1/5, Loss: 0.6996491597502271\nEpoch 1/5, Validation Accuracy: 50.97%\nEpoch 2/5, Loss: 0.694748653232722\nEpoch 2/5, Validation Accuracy: 50.00%\nEpoch 3/5, Loss: 0.6983968378430572\nEpoch 3/5, Validation Accuracy: 50.28%\nEpoch 4/5, Loss: 0.6976875926249594\nEpoch 4/5, Validation Accuracy: 50.00%\nEpoch 5/5, Loss: 0.6988420598414722\nEpoch 5/5, Validation Accuracy: 50.35%\nFold 3/3\nEpoch 1/5, Loss: 0.6965940436605591\nEpoch 1/5, Validation Accuracy: 48.41%\nEpoch 2/5, Loss: 0.695357051343549\nEpoch 2/5, Validation Accuracy: 51.59%\nEpoch 3/5, Loss: 0.6983186352318822\nEpoch 3/5, Validation Accuracy: 48.41%\nEpoch 4/5, Loss: 0.6982994629533251\nEpoch 4/5, Validation Accuracy: 48.41%\nEpoch 5/5, Loss: 0.6981744324963396\nEpoch 5/5, Validation Accuracy: 51.59%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 16:38:06,525] Trial 4 finished with value: 0.5083102493074793 and parameters: {'lr': 0.011046503969720027}. Best is trial 0 with value: 0.8331024930747922.\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Best Learning Rate for VGG-16: 0.00010837400852480871\nTotal trainable parameters: 7,087,618\n\nEvaluating on Fold 1/3\nEpoch 1/5, Loss: 0.5785066411310796\nEpoch 1/5, Validation Accuracy: 75.62%\nEpoch 2/5, Loss: 0.46792233994652555\nEpoch 2/5, Validation Accuracy: 77.77%\nEpoch 3/5, Loss: 0.4368656005154657\nEpoch 3/5, Validation Accuracy: 77.63%\nEpoch 4/5, Loss: 0.4045661822866998\nEpoch 4/5, Validation Accuracy: 76.80%\nEpoch 5/5, Loss: 0.3995853181701997\nEpoch 5/5, Validation Accuracy: 81.65%\n\nEvaluating on Fold 2/3\nEpoch 1/5, Loss: 0.37996076335564505\nEpoch 1/5, Validation Accuracy: 84.28%\nEpoch 2/5, Loss: 0.3767143885569019\nEpoch 2/5, Validation Accuracy: 84.56%\nEpoch 3/5, Loss: 0.35357557368871256\nEpoch 3/5, Validation Accuracy: 84.35%\nEpoch 4/5, Loss: 0.34999272927065583\nEpoch 4/5, Validation Accuracy: 82.96%\nEpoch 5/5, Loss: 0.3334822432029972\nEpoch 5/5, Validation Accuracy: 83.59%\n\nEvaluating on Fold 3/3\nEpoch 1/5, Loss: 0.33613505646668745\nEpoch 1/5, Validation Accuracy: 84.63%\nEpoch 2/5, Loss: 0.32792519012373456\nEpoch 2/5, Validation Accuracy: 85.66%\nEpoch 3/5, Loss: 0.30909983204543917\nEpoch 3/5, Validation Accuracy: 84.49%\nEpoch 4/5, Loss: 0.2950136475059209\nEpoch 4/5, Validation Accuracy: 83.10%\nEpoch 5/5, Loss: 0.30506488557349254\nEpoch 5/5, Validation Accuracy: 84.28%\nFold 1 Metrics:\nAccuracy: 0.82, Precision: 0.81, Recall: 0.84, F1-Score: 0.82\nConfusion Matrix:\n[[1491  350]\n [ 284 1484]]\nFold 2 Metrics:\nAccuracy: 0.84, Precision: 0.85, Recall: 0.83, F1-Score: 0.84\nConfusion Matrix:\n[[1547  260]\n [ 305 1497]]\nFold 3 Metrics:\nAccuracy: 0.86, Precision: 0.82, Recall: 0.93, F1-Score: 0.87\nConfusion Matrix:\n[[1392  373]\n [ 137 1706]]\n\nAverage Metrics Across Folds:\nAccuracy: 0.84, Precision: 0.83, Recall: 0.87, F1-Score: 0.85\nConfusion Matrix (sum of all folds):\n[[4430  983]\n [ 726 4687]]\n","output_type":"stream"}],"execution_count":13}]}