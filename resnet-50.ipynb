{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10295959,"sourceType":"datasetVersion","datasetId":6372503}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom torchvision import transforms, models, datasets\nimport torch.optim as optim\nimport torch.nn as nn\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, precision_recall_fscore_support)\nfrom transformers import ViTForImageClassification, ViTFeatureExtractor\nimport optuna","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-25T13:44:36.836109Z","iopub.execute_input":"2024-12-25T13:44:36.836437Z","iopub.status.idle":"2024-12-25T13:44:52.536814Z","shell.execute_reply.started":"2024-12-25T13:44:36.836412Z","shell.execute_reply":"2024-12-25T13:44:52.536121Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"dataset_dir = '/kaggle/input/deepfake/DeepFake'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T13:57:21.480842Z","iopub.execute_input":"2024-12-25T13:57:21.481044Z","iopub.status.idle":"2024-12-25T13:57:21.484785Z","shell.execute_reply.started":"2024-12-25T13:57:21.481026Z","shell.execute_reply":"2024-12-25T13:57:21.483675Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"transform_train = transforms.Compose([\n    transforms.Resize((224, 224)),  \n    transforms.ToTensor(),  \n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(p=0.2),\n    transforms.RandomRotation(15),\n    transforms.RandomCrop(224, padding=10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.RandomAffine(degrees=20, scale=(0.8, 1.2), shear=10),\n    transforms.RandomErasing(p=0.3),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  \n])\n\ntransform_val_test = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T13:57:22.174095Z","iopub.execute_input":"2024-12-25T13:57:22.174456Z","iopub.status.idle":"2024-12-25T13:57:22.179990Z","shell.execute_reply.started":"2024-12-25T13:57:22.174424Z","shell.execute_reply":"2024-12-25T13:57:22.179293Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Load the dataset\nfrom torchvision.datasets import ImageFolder\ndataset = ImageFolder(root=dataset_dir, transform=transform_train)\nprint(\"Classes:\", dataset.classes)\nprint(\"Class-to-Index Mapping:\", dataset.class_to_idx)\nprint(\"Number of Samples:\", len(dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T13:57:29.115162Z","iopub.execute_input":"2024-12-25T13:57:29.115510Z","iopub.status.idle":"2024-12-25T13:57:33.666001Z","shell.execute_reply.started":"2024-12-25T13:57:29.115486Z","shell.execute_reply":"2024-12-25T13:57:33.665293Z"}},"outputs":[{"name":"stdout","text":"Classes: ['Fake', 'Real']\nClass-to-Index Mapping: {'Fake': 0, 'Real': 1}\nNumber of Samples: 10826\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def get_model(model_name):\n    if model_name == \"resnet-50\":\n        # Load pre-trained ResNet-50 model\n        model = models.resnet50(pretrained=True)\n        \n        # Freeze all layers initially\n        for param in model.parameters():\n            param.requires_grad = False\n        \n        # Update the fully connected layer for binary classification\n        model.fc = nn.Linear(model.fc.in_features, 2)\n        \n        return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T13:57:47.778174Z","iopub.execute_input":"2024-12-25T13:57:47.778519Z","iopub.status.idle":"2024-12-25T13:57:47.782737Z","shell.execute_reply.started":"2024-12-25T13:57:47.778493Z","shell.execute_reply":"2024-12-25T13:57:47.781963Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Calculate metrics function\ndef calculate_metrics(model, loader, device):\n    \n    # Set the model to evaluation mode (disables dropout)\n    model.eval()\n\n    # Lists to store true labels and predicted labels\n    all_labels = []\n    all_predictions = []\n\n    # Disabling gradient computation\n    with torch.no_grad():\n        for images, labels in loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n             # Get predicted labels by taking the argmax (most likely class)\n            _, predicted = torch.max(outputs, 1)\n            all_labels.extend(labels.cpu().numpy())\n            all_predictions.extend(predicted.cpu().numpy())\n\n     # Calculate the confusion matrix,which give TN, FP, FN, and TP\n    conf_matrix = confusion_matrix(all_labels, all_predictions)\n    # Unpack the confusion matrix into four components: TN, FP, FN, TP\n    TN, FP, FN, TP = conf_matrix.ravel() \n\n    total = conf_matrix.sum()\n    accuracy = (TP + TN) / total if total > 0 else 0.0\n    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n    \n    return accuracy, precision, recall, f1, conf_matrix\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T13:57:51.705404Z","iopub.execute_input":"2024-12-25T13:57:51.705814Z","iopub.status.idle":"2024-12-25T13:57:51.714762Z","shell.execute_reply.started":"2024-12-25T13:57:51.705776Z","shell.execute_reply":"2024-12-25T13:57:51.713762Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Train the model function with validation accuracy printed after each epoch\ndef train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5):\n    # Variable to track the best validation accuracy\n    best_val_accuracy = 0\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n         # Iterate over batches in the training data\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n        \n        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n        # Validation phase\n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        val_accuracy = 100 * correct / total\n        print(f\"Epoch {epoch+1}/{epochs}, Validation Accuracy: {val_accuracy:.2f}%\")\n        \n        if val_accuracy > best_val_accuracy:\n            best_val_accuracy = val_accuracy\n    \n    return best_val_accuracy\n\n# Device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Cross-validation setup\nnum_folds = 3\nkf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T13:57:56.726943Z","iopub.execute_input":"2024-12-25T13:57:56.727244Z","iopub.status.idle":"2024-12-25T13:57:56.817712Z","shell.execute_reply.started":"2024-12-25T13:57:56.727198Z","shell.execute_reply":"2024-12-25T13:57:56.816731Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def objective(trial, model_name):\n    # Get a suggested learning rate from Optuna\n    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n    \n    # Initialize the model with dropout\n    model = get_model(model_name).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    \n    val_accuracies = []\n    for fold_idx, (train_val_idx, test_idx) in enumerate(kf.split(dataset)):\n        print(f\"Fold {fold_idx + 1}/{num_folds}\")\n        \n        # Create training/validation split\n        train_val_data = Subset(dataset, train_val_idx)\n        test_data = Subset(dataset, test_idx)\n        \n        train_size = int(0.8 * len(train_val_data))\n        val_size = len(train_val_data) - train_size\n        train_data, val_data = torch.utils.data.random_split(\n            train_val_data, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n        )\n        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n        \n        # Train the model and get validation accuracy\n        train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)\n        \n        # Evaluate on validation set\n        val_accuracy, _, _, _, _ = calculate_metrics(model, val_loader, device)\n        val_accuracies.append(val_accuracy)\n    \n    # Return the average validation accuracy across all folds as the objective value\n    return np.mean(val_accuracies)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T13:58:06.899301Z","iopub.execute_input":"2024-12-25T13:58:06.899599Z","iopub.status.idle":"2024-12-25T13:58:06.905924Z","shell.execute_reply.started":"2024-12-25T13:58:06.899575Z","shell.execute_reply":"2024-12-25T13:58:06.905032Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def evaluate_test_set(model_name, best_lr):\n    # Initialize model with the best learning rate\n    model = get_model(model_name).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=best_lr)\n    criterion = nn.CrossEntropyLoss()\n\n    fold_metrics = []\n    for fold_idx, (train_val_idx, test_idx) in enumerate(kf.split(dataset)):\n        print(f\"\\nEvaluating on Fold {fold_idx + 1}/{num_folds}\")\n        \n        # Create training/validation split\n        train_val_data = Subset(dataset, train_val_idx)\n        test_data = Subset(dataset, test_idx)\n        \n        train_size = int(0.8 * len(train_val_data))\n        val_size = len(train_val_data) - train_size\n        train_data, val_data = torch.utils.data.random_split(\n            train_val_data, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n        )\n        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n        \n        # Train the model\n        train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)\n        \n        # Evaluate on the test set\n        test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n        fold_metrics.append(calculate_metrics(model, test_loader, device))\n    \n    # Print metrics for each fold\n    for fold_idx, metrics in enumerate(fold_metrics):\n        accuracy, precision, recall, f1, conf_matrix = metrics\n        print(f\"Fold {fold_idx + 1} Metrics:\")\n        print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}\")\n        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n\n# Calculate average metrics across folds\n    avg_accuracy = np.mean([metrics[0] for metrics in fold_metrics])\n    avg_precision = np.mean([metrics[1] for metrics in fold_metrics])\n    avg_recall = np.mean([metrics[2] for metrics in fold_metrics])\n    avg_f1 = np.mean([metrics[3] for metrics in fold_metrics])\n    total_conf_matrix = np.sum([metrics[4] for metrics in fold_metrics], axis=0)\n\n    print(\"\\nAverage Metrics Across Folds:\")\n    print(f\"Accuracy: {avg_accuracy:.2f}, Precision: {avg_precision:.2f}, Recall: {avg_recall:.2f}, F1-Score: {avg_f1:.2f}\")\n    print(f\"Confusion Matrix (sum of all folds):\\n{total_conf_matrix}\")\n\n\n# Optuna Optimization and Final Testing\nfor model_name in [\"resnet-50\"]:\n    print(f\"\\nOptimizing for {model_name.upper()}...\")\n    study = optuna.create_study(direction='maximize')\n    study.optimize(lambda trial: objective(trial, model_name), n_trials=5)  # You can increase the number of trials if needed\n\n    # Best learning rate found for the model\n    best_lr = study.best_params['lr']\n    print(f\"Best Learning Rate for {model_name.upper()}: {best_lr}\")\n\n    # Evaluate on test sets for each fold\n    evaluate_test_set(model_name, best_lr)\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T13:59:42.041658Z","iopub.execute_input":"2024-12-25T13:59:42.041945Z","iopub.status.idle":"2024-12-25T16:50:29.954935Z","shell.execute_reply.started":"2024-12-25T13:59:42.041923Z","shell.execute_reply":"2024-12-25T16:50:29.954019Z"}},"outputs":[{"name":"stderr","text":"[I 2024-12-25 13:59:42,048] A new study created in memory with name: no-name-77a8874e-b7fc-4df5-a6d0-177901710fb6\n","output_type":"stream"},{"name":"stdout","text":"\nOptimizing for RESNET-50...\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-14-2e749100ab16>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 211MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Fold 1/3\nEpoch 1/5, Loss: 2.6325327655228463\nEpoch 1/5, Validation Accuracy: 66.83%\nEpoch 2/5, Loss: 1.9378970094148624\nEpoch 2/5, Validation Accuracy: 60.39%\nEpoch 3/5, Loss: 2.256535168840082\nEpoch 3/5, Validation Accuracy: 68.01%\nEpoch 4/5, Loss: 2.631577669586266\nEpoch 4/5, Validation Accuracy: 54.85%\nEpoch 5/5, Loss: 2.0797723225467113\nEpoch 5/5, Validation Accuracy: 67.38%\nFold 2/3\nEpoch 1/5, Loss: 2.061254018907389\nEpoch 1/5, Validation Accuracy: 60.66%\nEpoch 2/5, Loss: 2.404883705120719\nEpoch 2/5, Validation Accuracy: 69.67%\nEpoch 3/5, Loss: 3.675904724808688\nEpoch 3/5, Validation Accuracy: 69.32%\nEpoch 4/5, Loss: 3.4277701122655393\nEpoch 4/5, Validation Accuracy: 61.01%\nEpoch 5/5, Loss: 3.0723594171895505\nEpoch 5/5, Validation Accuracy: 68.21%\nFold 3/3\nEpoch 1/5, Loss: 2.8197471545546096\nEpoch 1/5, Validation Accuracy: 71.33%\nEpoch 2/5, Loss: 2.304173856315033\nEpoch 2/5, Validation Accuracy: 64.06%\nEpoch 3/5, Loss: 3.129160007060562\nEpoch 3/5, Validation Accuracy: 66.07%\nEpoch 4/5, Loss: 2.4627633068443004\nEpoch 4/5, Validation Accuracy: 63.30%\nEpoch 5/5, Loss: 1.9811185325048246\nEpoch 5/5, Validation Accuracy: 70.57%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 14:28:19,839] Trial 0 finished with value: 0.6823638042474608 and parameters: {'lr': 0.04722758116217684}. Best is trial 0 with value: 0.6823638042474608.\n<ipython-input-14-2e749100ab16>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Fold 1/3\nEpoch 1/5, Loss: 2.571131027205873\nEpoch 1/5, Validation Accuracy: 53.88%\nEpoch 2/5, Loss: 2.0780664336615504\nEpoch 2/5, Validation Accuracy: 50.97%\nEpoch 3/5, Loss: 2.019721493536596\nEpoch 3/5, Validation Accuracy: 53.46%\nEpoch 4/5, Loss: 2.787081377282327\nEpoch 4/5, Validation Accuracy: 59.83%\nEpoch 5/5, Loss: 1.8184023313430133\nEpoch 5/5, Validation Accuracy: 70.57%\nFold 2/3\nEpoch 1/5, Loss: 1.8382339441315245\nEpoch 1/5, Validation Accuracy: 62.74%\nEpoch 2/5, Loss: 1.6980435230784654\nEpoch 2/5, Validation Accuracy: 69.53%\nEpoch 3/5, Loss: 1.694767294338395\nEpoch 3/5, Validation Accuracy: 56.51%\nEpoch 4/5, Loss: 1.7861252053337202\nEpoch 4/5, Validation Accuracy: 67.73%\nEpoch 5/5, Loss: 2.319406638817234\nEpoch 5/5, Validation Accuracy: 67.94%\nFold 3/3\nEpoch 1/5, Loss: 2.0631778734165\nEpoch 1/5, Validation Accuracy: 65.93%\nEpoch 2/5, Loss: 1.8279962073702838\nEpoch 2/5, Validation Accuracy: 70.64%\nEpoch 3/5, Loss: 1.896511474696312\nEpoch 3/5, Validation Accuracy: 59.21%\nEpoch 4/5, Loss: 2.4521529363334507\nEpoch 4/5, Validation Accuracy: 69.25%\nEpoch 5/5, Loss: 1.5050068747931422\nEpoch 5/5, Validation Accuracy: 57.76%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 14:56:46,915] Trial 1 finished with value: 0.6525854108956602 and parameters: {'lr': 0.03702599268428947}. Best is trial 0 with value: 0.6823638042474608.\n<ipython-input-14-2e749100ab16>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Fold 1/3\nEpoch 1/5, Loss: 0.7012037144181478\nEpoch 1/5, Validation Accuracy: 53.81%\nEpoch 2/5, Loss: 0.6798062192800954\nEpoch 2/5, Validation Accuracy: 61.98%\nEpoch 3/5, Loss: 0.662187484087865\nEpoch 3/5, Validation Accuracy: 60.04%\nEpoch 4/5, Loss: 0.6485887578179165\nEpoch 4/5, Validation Accuracy: 63.37%\nEpoch 5/5, Loss: 0.6380240581312232\nEpoch 5/5, Validation Accuracy: 64.40%\nFold 2/3\nEpoch 1/5, Loss: 0.6317433649005152\nEpoch 1/5, Validation Accuracy: 64.82%\nEpoch 2/5, Loss: 0.6264294142222536\nEpoch 2/5, Validation Accuracy: 65.37%\nEpoch 3/5, Loss: 0.6167103565858872\nEpoch 3/5, Validation Accuracy: 68.49%\nEpoch 4/5, Loss: 0.6115542189192377\nEpoch 4/5, Validation Accuracy: 68.70%\nEpoch 5/5, Loss: 0.6097571566618608\nEpoch 5/5, Validation Accuracy: 68.63%\nFold 3/3\nEpoch 1/5, Loss: 0.6017608901084457\nEpoch 1/5, Validation Accuracy: 68.91%\nEpoch 2/5, Loss: 0.601945873782121\nEpoch 2/5, Validation Accuracy: 68.91%\nEpoch 3/5, Loss: 0.5975486820573965\nEpoch 3/5, Validation Accuracy: 70.71%\nEpoch 4/5, Loss: 0.5964100978321792\nEpoch 4/5, Validation Accuracy: 69.53%\nEpoch 5/5, Loss: 0.591508106796781\nEpoch 5/5, Validation Accuracy: 68.14%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 15:24:52,328] Trial 2 finished with value: 0.6726685133887349 and parameters: {'lr': 2.5927378167889653e-05}. Best is trial 0 with value: 0.6823638042474608.\n<ipython-input-14-2e749100ab16>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Fold 1/3\nEpoch 1/5, Loss: 0.7002603800257267\nEpoch 1/5, Validation Accuracy: 52.22%\nEpoch 2/5, Loss: 0.6806751239365636\nEpoch 2/5, Validation Accuracy: 59.00%\nEpoch 3/5, Loss: 0.667740376614734\nEpoch 3/5, Validation Accuracy: 60.60%\nEpoch 4/5, Loss: 0.6595369570821689\nEpoch 4/5, Validation Accuracy: 61.98%\nEpoch 5/5, Loss: 0.6484514231181276\nEpoch 5/5, Validation Accuracy: 65.03%\nFold 2/3\nEpoch 1/5, Loss: 0.641383278435765\nEpoch 1/5, Validation Accuracy: 65.93%\nEpoch 2/5, Loss: 0.6370106481056845\nEpoch 2/5, Validation Accuracy: 66.55%\nEpoch 3/5, Loss: 0.630670487222092\nEpoch 3/5, Validation Accuracy: 66.90%\nEpoch 4/5, Loss: 0.6236219462110193\nEpoch 4/5, Validation Accuracy: 67.45%\nEpoch 5/5, Loss: 0.619940670484996\nEpoch 5/5, Validation Accuracy: 69.32%\nFold 3/3\nEpoch 1/5, Loss: 0.6201555946255257\nEpoch 1/5, Validation Accuracy: 67.80%\nEpoch 2/5, Loss: 0.6156942110035301\nEpoch 2/5, Validation Accuracy: 68.01%\nEpoch 3/5, Loss: 0.6077481577409565\nEpoch 3/5, Validation Accuracy: 67.45%\nEpoch 4/5, Loss: 0.607229878889263\nEpoch 4/5, Validation Accuracy: 68.56%\nEpoch 5/5, Loss: 0.5997641361550073\nEpoch 5/5, Validation Accuracy: 68.28%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 15:52:44,336] Trial 3 finished with value: 0.6627423822714681 and parameters: {'lr': 1.8166961537163752e-05}. Best is trial 0 with value: 0.6823638042474608.\n<ipython-input-14-2e749100ab16>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Fold 1/3\nEpoch 1/5, Loss: 0.6882135703418795\nEpoch 1/5, Validation Accuracy: 58.38%\nEpoch 2/5, Loss: 0.6643620584551142\nEpoch 2/5, Validation Accuracy: 61.36%\nEpoch 3/5, Loss: 0.6495809396986145\nEpoch 3/5, Validation Accuracy: 64.06%\nEpoch 4/5, Loss: 0.6367074511327796\nEpoch 4/5, Validation Accuracy: 65.65%\nEpoch 5/5, Loss: 0.6260198031999789\nEpoch 5/5, Validation Accuracy: 67.45%\nFold 2/3\nEpoch 1/5, Loss: 0.623858847835446\nEpoch 1/5, Validation Accuracy: 67.80%\nEpoch 2/5, Loss: 0.6193809943963151\nEpoch 2/5, Validation Accuracy: 68.35%\nEpoch 3/5, Loss: 0.6130160134470923\nEpoch 3/5, Validation Accuracy: 68.77%\nEpoch 4/5, Loss: 0.608506024213127\nEpoch 4/5, Validation Accuracy: 66.83%\nEpoch 5/5, Loss: 0.6023563862834846\nEpoch 5/5, Validation Accuracy: 67.94%\nFold 3/3\nEpoch 1/5, Loss: 0.5997128598597827\nEpoch 1/5, Validation Accuracy: 68.07%\nEpoch 2/5, Loss: 0.5957922349318615\nEpoch 2/5, Validation Accuracy: 70.36%\nEpoch 3/5, Loss: 0.5953457421360754\nEpoch 3/5, Validation Accuracy: 68.84%\nEpoch 4/5, Loss: 0.596135911526601\nEpoch 4/5, Validation Accuracy: 69.04%\nEpoch 5/5, Loss: 0.5889478393351835\nEpoch 5/5, Validation Accuracy: 68.84%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 16:20:53,965] Trial 4 finished with value: 0.6798245614035087 and parameters: {'lr': 3.070691748554705e-05}. Best is trial 0 with value: 0.6823638042474608.\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Best Learning Rate for RESNET-50: 0.04722758116217684\n\nEvaluating on Fold 1/3\nEpoch 1/5, Loss: 3.1195410597060924\nEpoch 1/5, Validation Accuracy: 64.27%\nEpoch 2/5, Loss: 2.4474058740705416\nEpoch 2/5, Validation Accuracy: 55.61%\nEpoch 3/5, Loss: 2.312732575348069\nEpoch 3/5, Validation Accuracy: 55.19%\nEpoch 4/5, Loss: 2.3110913390612735\nEpoch 4/5, Validation Accuracy: 63.64%\nEpoch 5/5, Loss: 2.2533526660987686\nEpoch 5/5, Validation Accuracy: 66.55%\n\nEvaluating on Fold 2/3\nEpoch 1/5, Loss: 2.6921204613387912\nEpoch 1/5, Validation Accuracy: 66.14%\nEpoch 2/5, Loss: 1.9200723734349836\nEpoch 2/5, Validation Accuracy: 70.22%\nEpoch 3/5, Loss: 2.9706147125412747\nEpoch 3/5, Validation Accuracy: 70.22%\nEpoch 4/5, Loss: 2.6655379155064156\nEpoch 4/5, Validation Accuracy: 68.63%\nEpoch 5/5, Loss: 3.5381527645153237\nEpoch 5/5, Validation Accuracy: 70.36%\n\nEvaluating on Fold 3/3\nEpoch 1/5, Loss: 3.2501211182847207\nEpoch 1/5, Validation Accuracy: 74.03%\nEpoch 2/5, Loss: 2.507180038242709\nEpoch 2/5, Validation Accuracy: 62.40%\nEpoch 3/5, Loss: 2.588613609418026\nEpoch 3/5, Validation Accuracy: 68.84%\nEpoch 4/5, Loss: 2.090511926135964\nEpoch 4/5, Validation Accuracy: 58.86%\nEpoch 5/5, Loss: 2.405390172044217\nEpoch 5/5, Validation Accuracy: 71.33%\nFold 1 Metrics:\nAccuracy: 0.65, Precision: 0.59, Recall: 0.93, F1-Score: 0.72\nConfusion Matrix:\n[[ 708 1133]\n [ 130 1638]]\nFold 2 Metrics:\nAccuracy: 0.70, Precision: 0.65, Recall: 0.86, F1-Score: 0.74\nConfusion Matrix:\n[[ 969  838]\n [ 254 1548]]\nFold 3 Metrics:\nAccuracy: 0.72, Precision: 0.73, Recall: 0.71, F1-Score: 0.72\nConfusion Matrix:\n[[1285  480]\n [ 530 1313]]\n\nAverage Metrics Across Folds:\nAccuracy: 0.69, Precision: 0.66, Recall: 0.83, F1-Score: 0.73\nConfusion Matrix (sum of all folds):\n[[2962 2451]\n [ 914 4499]]\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"def initialize_model(name):\n    if name == \"resnet-50\":\n        model = models.resnet50(pretrained=True)\n        \n        # Freeze all layers initially\n        for param in model.parameters():\n            param.requires_grad = False\n            \n        # Unfreeze the final two residual blocks (layer3 and layer4)\n        for layer in [model.layer3, model.layer4]:\n            for param in layer.parameters():\n                param.requires_grad = True\n                \n        # Unfreeze and modify the final fully connected layer\n        model.fc = nn.Linear(model.fc.in_features, 2)\n        \n        # Print layer status\n        def count_trainable_params(model):\n            return sum(p.numel() for p in model.parameters() if p.requires_grad)\n            \n        print(f\"Total trainable parameters: {count_trainable_params(model):,}\")\n        \n    else:\n        raise ValueError(\"Model name must be 'resnet-50'\")\n    \n    return model\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T16:50:57.606476Z","iopub.execute_input":"2024-12-25T16:50:57.606790Z","iopub.status.idle":"2024-12-25T16:50:57.612060Z","shell.execute_reply.started":"2024-12-25T16:50:57.606766Z","shell.execute_reply":"2024-12-25T16:50:57.611074Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# for fine tunning\ndef objective(trial, model_name):\n    # Get a suggested learning rate from Optuna\n    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n    \n    # Initialize the model with dropout\n    model = initialize_model(model_name).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    \n    val_accuracies = []\n    for fold_idx, (train_val_idx, test_idx) in enumerate(kf.split(dataset)):\n        print(f\"Fold {fold_idx + 1}/{num_folds}\")\n        \n        # Create training/validation split\n        train_val_data = Subset(dataset, train_val_idx)\n        test_data = Subset(dataset, test_idx)\n        \n        train_size = int(0.8 * len(train_val_data))\n        val_size = len(train_val_data) - train_size\n        train_data, val_data = torch.utils.data.random_split(\n            train_val_data, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n        )\n        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n        \n        # Train the model and get validation accuracy\n        train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)\n        \n        # Evaluate on validation set\n        val_accuracy, _, _, _, _ = calculate_metrics(model, val_loader, device)\n        val_accuracies.append(val_accuracy)\n    \n    # Return the average validation accuracy across all folds as the objective value\n    return np.mean(val_accuracies)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T16:51:04.547827Z","iopub.execute_input":"2024-12-25T16:51:04.548140Z","iopub.status.idle":"2024-12-25T16:51:04.554609Z","shell.execute_reply.started":"2024-12-25T16:51:04.548112Z","shell.execute_reply":"2024-12-25T16:51:04.553805Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def evaluate_test_set(model_name, best_lr):\n    # Initialize model with the best learning rate\n    model = initialize_model(model_name).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=best_lr)\n    criterion = nn.CrossEntropyLoss()\n\n    fold_metrics = []\n    for fold_idx, (train_val_idx, test_idx) in enumerate(kf.split(dataset)):\n        print(f\"\\nEvaluating on Fold {fold_idx + 1}/{num_folds}\")\n        \n        # Create training/validation split\n        train_val_data = Subset(dataset, train_val_idx)\n        test_data = Subset(dataset, test_idx)\n        \n        train_size = int(0.8 * len(train_val_data))\n        val_size = len(train_val_data) - train_size\n        train_data, val_data = torch.utils.data.random_split(\n            train_val_data, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n        )\n        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n        \n        # Train the model\n        train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)\n        \n        # Evaluate on the test set\n        test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n        fold_metrics.append(calculate_metrics(model, test_loader, device))\n    \n    # Print metrics for each fold\n    for fold_idx, metrics in enumerate(fold_metrics):\n        accuracy, precision, recall, f1, conf_matrix = metrics\n        print(f\"Fold {fold_idx + 1} Metrics:\")\n        print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}\")\n        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n\n# Calculate average metrics across folds\n    avg_accuracy = np.mean([metrics[0] for metrics in fold_metrics])\n    avg_precision = np.mean([metrics[1] for metrics in fold_metrics])\n    avg_recall = np.mean([metrics[2] for metrics in fold_metrics])\n    avg_f1 = np.mean([metrics[3] for metrics in fold_metrics])\n    total_conf_matrix = np.sum([metrics[4] for metrics in fold_metrics], axis=0)\n\n    print(\"\\nAverage Metrics Across Folds:\")\n    print(f\"Accuracy: {avg_accuracy:.2f}, Precision: {avg_precision:.2f}, Recall: {avg_recall:.2f}, F1-Score: {avg_f1:.2f}\")\n    print(f\"Confusion Matrix (sum of all folds):\\n{total_conf_matrix}\")\n\n\n# Optuna Optimization and Final Testing\nfor model_name in [\"resnet-50\"]:\n    print(f\"\\nOptimizing for {model_name.upper()}...\")\n    study = optuna.create_study(direction='maximize')\n    study.optimize(lambda trial: objective(trial, model_name), n_trials=5)  # You can increase the number of trials if needed\n\n    # Best learning rate found for the model\n    best_lr = study.best_params['lr']\n    print(f\"Best Learning Rate for {model_name.upper()}: {best_lr}\")\n\n    # Evaluate on test sets for each fold\n    evaluate_test_set(model_name, best_lr)\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T16:51:56.601721Z","iopub.execute_input":"2024-12-25T16:51:56.602167Z","iopub.status.idle":"2024-12-25T20:11:49.100182Z","shell.execute_reply.started":"2024-12-25T16:51:56.602123Z","shell.execute_reply":"2024-12-25T20:11:49.099455Z"}},"outputs":[{"name":"stderr","text":"[I 2024-12-25 16:51:56,613] A new study created in memory with name: no-name-75644693-23bf-4baf-aeb7-7db581845812\n","output_type":"stream"},{"name":"stdout","text":"\nOptimizing for RESNET-50...\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-18-1c309b109a5c>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Total trainable parameters: 22,067,202\nFold 1/3\nEpoch 1/5, Loss: 0.7628418450856077\nEpoch 1/5, Validation Accuracy: 50.21%\nEpoch 2/5, Loss: 0.6497182636959118\nEpoch 2/5, Validation Accuracy: 62.26%\nEpoch 3/5, Loss: 0.5605222620687432\nEpoch 3/5, Validation Accuracy: 68.98%\nEpoch 4/5, Loss: 0.5117340568679473\nEpoch 4/5, Validation Accuracy: 67.66%\nEpoch 5/5, Loss: 0.44573503600958303\nEpoch 5/5, Validation Accuracy: 74.31%\nFold 2/3\nEpoch 1/5, Loss: 0.4175016579542371\nEpoch 1/5, Validation Accuracy: 72.85%\nEpoch 2/5, Loss: 0.3989502611410552\nEpoch 2/5, Validation Accuracy: 85.73%\nEpoch 3/5, Loss: 0.3773586157277144\nEpoch 3/5, Validation Accuracy: 83.03%\nEpoch 4/5, Loss: 0.35716825139127384\nEpoch 4/5, Validation Accuracy: 80.26%\nEpoch 5/5, Loss: 0.3510269730542246\nEpoch 5/5, Validation Accuracy: 82.48%\nFold 3/3\nEpoch 1/5, Loss: 0.35399011370226824\nEpoch 1/5, Validation Accuracy: 84.97%\nEpoch 2/5, Loss: 0.3452872964887988\nEpoch 2/5, Validation Accuracy: 86.08%\nEpoch 3/5, Loss: 0.32864953108255374\nEpoch 3/5, Validation Accuracy: 83.17%\nEpoch 4/5, Loss: 0.3121942537759549\nEpoch 4/5, Validation Accuracy: 85.04%\nEpoch 5/5, Loss: 0.31527806810252573\nEpoch 5/5, Validation Accuracy: 75.90%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 17:24:46,116] Trial 0 finished with value: 0.7890120036934443 and parameters: {'lr': 0.005736397688215054}. Best is trial 0 with value: 0.7890120036934443.\n<ipython-input-18-1c309b109a5c>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Total trainable parameters: 22,067,202\nFold 1/3\nEpoch 1/5, Loss: 0.8389237796404085\nEpoch 1/5, Validation Accuracy: 50.76%\nEpoch 2/5, Loss: 0.6455392796360986\nEpoch 2/5, Validation Accuracy: 70.15%\nEpoch 3/5, Loss: 0.5558758183737487\nEpoch 3/5, Validation Accuracy: 75.97%\nEpoch 4/5, Loss: 0.4914824048787849\nEpoch 4/5, Validation Accuracy: 78.19%\nEpoch 5/5, Loss: 0.4454140679612344\nEpoch 5/5, Validation Accuracy: 78.53%\nFold 2/3\nEpoch 1/5, Loss: 0.4184362186088088\nEpoch 1/5, Validation Accuracy: 82.20%\nEpoch 2/5, Loss: 0.4018844822987667\nEpoch 2/5, Validation Accuracy: 68.42%\nEpoch 3/5, Loss: 0.37788502386261746\nEpoch 3/5, Validation Accuracy: 84.76%\nEpoch 4/5, Loss: 0.36769635720147614\nEpoch 4/5, Validation Accuracy: 83.03%\nEpoch 5/5, Loss: 0.3661045098666987\nEpoch 5/5, Validation Accuracy: 80.68%\nFold 3/3\nEpoch 1/5, Loss: 0.35756829208102675\nEpoch 1/5, Validation Accuracy: 85.11%\nEpoch 2/5, Loss: 0.33971798510511936\nEpoch 2/5, Validation Accuracy: 73.68%\nEpoch 3/5, Loss: 0.3283819678903285\nEpoch 3/5, Validation Accuracy: 84.63%\nEpoch 4/5, Loss: 0.3225453713322213\nEpoch 4/5, Validation Accuracy: 85.32%\nEpoch 5/5, Loss: 0.32991481732926975\nEpoch 5/5, Validation Accuracy: 87.53%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 17:57:44,765] Trial 1 finished with value: 0.8289473684210527 and parameters: {'lr': 0.012675771576100597}. Best is trial 1 with value: 0.8289473684210527.\n<ipython-input-18-1c309b109a5c>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Total trainable parameters: 22,067,202\nFold 1/3\nEpoch 1/5, Loss: 0.6002792678155952\nEpoch 1/5, Validation Accuracy: 71.75%\nEpoch 2/5, Loss: 0.4484793386571315\nEpoch 2/5, Validation Accuracy: 78.67%\nEpoch 3/5, Loss: 0.3990535369729469\nEpoch 3/5, Validation Accuracy: 75.00%\nEpoch 4/5, Loss: 0.37039015750858667\nEpoch 4/5, Validation Accuracy: 85.25%\nEpoch 5/5, Loss: 0.36056571902491114\nEpoch 5/5, Validation Accuracy: 83.80%\nFold 2/3\nEpoch 1/5, Loss: 0.341909898743445\nEpoch 1/5, Validation Accuracy: 84.83%\nEpoch 2/5, Loss: 0.32491720768298893\nEpoch 2/5, Validation Accuracy: 84.00%\nEpoch 3/5, Loss: 0.31558664739955195\nEpoch 3/5, Validation Accuracy: 85.04%\nEpoch 4/5, Loss: 0.2971603394954244\nEpoch 4/5, Validation Accuracy: 85.25%\nEpoch 5/5, Loss: 0.2902698348898914\nEpoch 5/5, Validation Accuracy: 83.45%\nFold 3/3\nEpoch 1/5, Loss: 0.3060758417647188\nEpoch 1/5, Validation Accuracy: 86.63%\nEpoch 2/5, Loss: 0.2777114368110731\nEpoch 2/5, Validation Accuracy: 86.84%\nEpoch 3/5, Loss: 0.280753112506142\nEpoch 3/5, Validation Accuracy: 86.15%\nEpoch 4/5, Loss: 0.26561036590713166\nEpoch 4/5, Validation Accuracy: 88.57%\nEpoch 5/5, Loss: 0.26636855999903125\nEpoch 5/5, Validation Accuracy: 85.25%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 18:30:55,806] Trial 2 finished with value: 0.8333333333333334 and parameters: {'lr': 0.001172905989332636}. Best is trial 2 with value: 0.8333333333333334.\n<ipython-input-18-1c309b109a5c>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Total trainable parameters: 22,067,202\nFold 1/3\nEpoch 1/5, Loss: 0.5250162963873773\nEpoch 1/5, Validation Accuracy: 78.74%\nEpoch 2/5, Loss: 0.3996987050574129\nEpoch 2/5, Validation Accuracy: 82.48%\nEpoch 3/5, Loss: 0.3439591477589054\nEpoch 3/5, Validation Accuracy: 84.35%\nEpoch 4/5, Loss: 0.30796296235935466\nEpoch 4/5, Validation Accuracy: 83.93%\nEpoch 5/5, Loss: 0.2937195279239291\nEpoch 5/5, Validation Accuracy: 85.39%\nFold 2/3\nEpoch 1/5, Loss: 0.3003933663937927\nEpoch 1/5, Validation Accuracy: 87.67%\nEpoch 2/5, Loss: 0.266571542381911\nEpoch 2/5, Validation Accuracy: 90.10%\nEpoch 3/5, Loss: 0.2492460009554473\nEpoch 3/5, Validation Accuracy: 90.03%\nEpoch 4/5, Loss: 0.24263770470797028\nEpoch 4/5, Validation Accuracy: 90.24%\nEpoch 5/5, Loss: 0.23177979750692515\nEpoch 5/5, Validation Accuracy: 90.44%\nFold 3/3\nEpoch 1/5, Loss: 0.25104345093115915\nEpoch 1/5, Validation Accuracy: 89.89%\nEpoch 2/5, Loss: 0.23202985784460828\nEpoch 2/5, Validation Accuracy: 90.03%\nEpoch 3/5, Loss: 0.2250707123161021\nEpoch 3/5, Validation Accuracy: 89.96%\nEpoch 4/5, Loss: 0.20781346363174982\nEpoch 4/5, Validation Accuracy: 90.93%\nEpoch 5/5, Loss: 0.20729826012039712\nEpoch 5/5, Validation Accuracy: 90.37%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 19:04:00,353] Trial 3 finished with value: 0.881809787626962 and parameters: {'lr': 2.2016545182065265e-05}. Best is trial 3 with value: 0.881809787626962.\n<ipython-input-18-1c309b109a5c>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Total trainable parameters: 22,067,202\nFold 1/3\nEpoch 1/5, Loss: 0.5647225516606431\nEpoch 1/5, Validation Accuracy: 75.21%\nEpoch 2/5, Loss: 0.42392392118991407\nEpoch 2/5, Validation Accuracy: 80.54%\nEpoch 3/5, Loss: 0.3744371768848672\nEpoch 3/5, Validation Accuracy: 81.93%\nEpoch 4/5, Loss: 0.34109522180004015\nEpoch 4/5, Validation Accuracy: 81.16%\nEpoch 5/5, Loss: 0.3202399695446478\nEpoch 5/5, Validation Accuracy: 86.43%\nFold 2/3\nEpoch 1/5, Loss: 0.31769744887207096\nEpoch 1/5, Validation Accuracy: 85.80%\nEpoch 2/5, Loss: 0.30535349167512926\nEpoch 2/5, Validation Accuracy: 87.33%\nEpoch 3/5, Loss: 0.2950883157016164\nEpoch 3/5, Validation Accuracy: 87.60%\nEpoch 4/5, Loss: 0.27491019361585545\nEpoch 4/5, Validation Accuracy: 86.29%\nEpoch 5/5, Loss: 0.2743705428354648\nEpoch 5/5, Validation Accuracy: 87.26%\nFold 3/3\nEpoch 1/5, Loss: 0.26947216899520127\nEpoch 1/5, Validation Accuracy: 86.63%\nEpoch 2/5, Loss: 0.2671359562165829\nEpoch 2/5, Validation Accuracy: 87.26%\nEpoch 3/5, Loss: 0.25034323655768653\nEpoch 3/5, Validation Accuracy: 89.34%\nEpoch 4/5, Loss: 0.2479053891742427\nEpoch 4/5, Validation Accuracy: 86.98%\nEpoch 5/5, Loss: 0.2500188144860347\nEpoch 5/5, Validation Accuracy: 88.50%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-25 19:36:57,337] Trial 4 finished with value: 0.8721144967682365 and parameters: {'lr': 0.0008262218582997476}. Best is trial 3 with value: 0.881809787626962.\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Best Learning Rate for RESNET-50: 2.2016545182065265e-05\nTotal trainable parameters: 22,067,202\n\nEvaluating on Fold 1/3\nEpoch 1/5, Loss: 0.5310034758478238\nEpoch 1/5, Validation Accuracy: 79.02%\nEpoch 2/5, Loss: 0.3887972894294486\nEpoch 2/5, Validation Accuracy: 81.16%\nEpoch 3/5, Loss: 0.33442202185728276\nEpoch 3/5, Validation Accuracy: 83.03%\nEpoch 4/5, Loss: 0.31179434851388244\nEpoch 4/5, Validation Accuracy: 86.01%\nEpoch 5/5, Loss: 0.2818460930447552\nEpoch 5/5, Validation Accuracy: 85.60%\n\nEvaluating on Fold 2/3\nEpoch 1/5, Loss: 0.3027783467624727\nEpoch 1/5, Validation Accuracy: 88.16%\nEpoch 2/5, Loss: 0.2783394424625523\nEpoch 2/5, Validation Accuracy: 88.37%\nEpoch 3/5, Loss: 0.264151846794463\nEpoch 3/5, Validation Accuracy: 90.37%\nEpoch 4/5, Loss: 0.2540232158003591\nEpoch 4/5, Validation Accuracy: 89.06%\nEpoch 5/5, Loss: 0.2375289557388474\nEpoch 5/5, Validation Accuracy: 89.40%\n\nEvaluating on Fold 3/3\nEpoch 1/5, Loss: 0.2381005324217496\nEpoch 1/5, Validation Accuracy: 90.03%\nEpoch 2/5, Loss: 0.24118967984098097\nEpoch 2/5, Validation Accuracy: 89.34%\nEpoch 3/5, Loss: 0.21068351927794804\nEpoch 3/5, Validation Accuracy: 90.03%\nEpoch 4/5, Loss: 0.21228237069361117\nEpoch 4/5, Validation Accuracy: 88.30%\nEpoch 5/5, Loss: 0.20235024507862429\nEpoch 5/5, Validation Accuracy: 90.58%\nFold 1 Metrics:\nAccuracy: 0.87, Precision: 0.84, Recall: 0.92, F1-Score: 0.87\nConfusion Matrix:\n[[1522  319]\n [ 146 1622]]\nFold 2 Metrics:\nAccuracy: 0.89, Precision: 0.87, Recall: 0.93, F1-Score: 0.90\nConfusion Matrix:\n[[1557  250]\n [ 135 1667]]\nFold 3 Metrics:\nAccuracy: 0.92, Precision: 0.90, Recall: 0.95, F1-Score: 0.93\nConfusion Matrix:\n[[1577  188]\n [  89 1754]]\n\nAverage Metrics Across Folds:\nAccuracy: 0.90, Precision: 0.87, Recall: 0.93, F1-Score: 0.90\nConfusion Matrix (sum of all folds):\n[[4656  757]\n [ 370 5043]]\n","output_type":"stream"}],"execution_count":19}]}